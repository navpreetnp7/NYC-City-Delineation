{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## City district delineation using Graph Neural Networks\n",
    "\n",
    "### Graph Neural Networks\n",
    "\n",
    "\n",
    "Graph Neural Networks (GNNs) are a class of deep learning methods designed to perform inference on data described by graphs. GNNs are neural networks that can be directly applied to graphs, and provide an easy way to do node-level, edge-level, and graph-level prediction tasks. \n",
    "\n",
    "Anything that is composed of linked entities can be represented as a graph. Graphs are excellent tools to visualize relations between people, objects, and concepts. With graphs becoming more pervasive and richer with information, and artificial neural networks becoming more popular and capable, GNNs have become a powerful tool for many important applications.\n",
    "\n",
    "<img src='GNN.png' width=\"600\" height=\"600\">\n",
    "\n",
    "Graph neural networks can be created like any other neural network, using fully connected layers, convolutional layers, pooling layers, etc. The type and number of layers depend on the type and complexity of the graph data and the desired output.\n",
    "\n",
    "The GNN receives the formatted graph data as input and produces a vector of numerical values that represent relevant information about nodes and their relations. This vector representation is called “graph embedding.”\n",
    "\n",
    "One very popular GNN architecture is the graph convolutional neural network (GCN), which uses convolution layers to create graph embeddings. (Kipf, T.N. and Welling, M., 2016. Semi-supervised classification with graph convolutional networks. https://arxiv.org/pdf/1609.02907.pdf)\n",
    "\n",
    "In the recent years, a lot of work has been done on the problem of generalizing neural networks to work on arbitrarily structured graphs - Bruna, J., Zaremba, W., Szlam, A. and LeCun, Y., 2013. Spectral networks and locally connected networks on graphs. https://arxiv.org/pdf/1312.6203.pdf%20http://arxiv.org/abs/1312.6203.pdf,  Henaff, M., Bruna, J. and LeCun, Y., 2015. Deep convolutional networks on graph-structured data. https://arxiv.org/abs/1506.05163 etc.\n",
    "\n",
    " \n",
    "Few applications for graph neural networks:\n",
    "\n",
    "- Node classification: One of the powerful applications of GNNs is adding new information to nodes or filling gaps where information is missing. For example, say you are running a social network and you have spotted a few bot accounts. Now you want to find out if there are other bot accounts in your network. You can train a GNN to classify other users in the social network as “bot” or “not bot” based on how close their graph embeddings are to those of the known bots.\n",
    "\n",
    "- Edge prediction: Another way to put GNNs to use is to find new edges that can add value to the graph. Going back to our social network, a GNN can find users (nodes) who are close to you in embedding space but who aren’t your friends yet (i.e., there isn’t an edge connecting you to each other). These users can then be introduced to you as friend suggestions.\n",
    "\n",
    "- Clustering: GNNs can glean new structural information from graphs. For example, in a social network where everyone is in one way or another related to others (through friends, or friends of friends, etc.), the GNN can find nodes that form clusters in the embedding space.\n",
    "\n",
    "A comprehensive tutorial on GNNs by Stanford is available on Youtube: https://www.youtube.com/watch?v=JAB_plj2rbA&list=PLoROMvodv4rPLKxIpqhjhPgdQy7imNkDn\n",
    "\n",
    "### GNN for city delineation\n",
    "\n",
    "Here, we demonstrate an application for GNN for city borough delineation. The relationships among various entities such as interaction among people, intra-city mobility, social media interactions can be interpreted in terms of graphs with many features associated with nodes, edges. \n",
    "\n",
    "We will use the LEHD mobility network among zip codes in NYC and use it to learn the corresponding borough of zip codes (nodes) in the city. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data overview\n",
    "\n",
    "The LEHD mobility matrix contains the commute numbers between the home and work zip codes of the population..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin</th>\n",
       "      <th>destination</th>\n",
       "      <th>weight</th>\n",
       "      <th>initialFeat</th>\n",
       "      <th>true_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11436</td>\n",
       "      <td>10009</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11436</td>\n",
       "      <td>10011</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11436</td>\n",
       "      <td>10013</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11436</td>\n",
       "      <td>10019</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11436</td>\n",
       "      <td>10021</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   origin  destination  weight  initialFeat  true_label\n",
       "0   11436        10009       1          4.0           4\n",
       "1   11436        10011       1          4.0           4\n",
       "2   11436        10013       1          4.0           4\n",
       "3   11436        10019       1          4.0           4\n",
       "4   11436        10021       1          4.0           4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/zips_merged.csv', delimiter=',')\n",
    "data = data.rename(columns={'total': 'weight', 'w_zip':'origin', 'h_zip':'destination'})\n",
    "data = data[data.destination.isin(data.origin.unique())]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the house price feature into the dataset\n",
    "\n",
    "housePrice = pd.read_csv('data/zipcode_housePrice.csv', delimiter=',')\n",
    "weights = [5000,12500,17500,22500,27500,32500,37500,45000,55000,65000,75000,85000\n",
    "                    ,95000,112500,137500,162500,187500,225000,275000,350000,450000,625000,875000\n",
    "                        ,1250000,1750000,2000000]\n",
    "for i in range(len(weights)):\n",
    "    housePrice.iloc[i,2:] = housePrice.iloc[i,2:]*weights[i]\n",
    "housePrice.iloc[:,1] [housePrice.iloc[:,1] == 0] = 1\n",
    "\n",
    "tmp = (housePrice.iloc[:,2:] != 0 ).sum(axis=1)\n",
    "tmp[tmp == 0] = 1\n",
    "housePrice = pd.concat([housePrice.iloc[:,0],housePrice.iloc[:,2:].sum(axis=1) / tmp ], axis = 1 )\n",
    "housePrice.rename(columns={'ZIPCODE':'destination', 0: 'house_price'}, inplace=True)\n",
    "housePrice['house_price'] = housePrice['house_price']/housePrice['house_price'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the area size feature into the dataset\n",
    "\n",
    "area = pd.read_csv('data/zips_area.csv', delimiter=',')\n",
    "area = area.iloc[:,:2]\n",
    "area.rename(columns={'ZIPCODE':'destination', 'AREA' : 'area'}, inplace=True)\n",
    "areas = area.copy()\n",
    "area['area'] = area['area']/area['area'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the income level feature into the dataset\n",
    "\n",
    "income = pd.read_csv('data/zipcode_income.csv', delimiter=',')\n",
    "income = income.iloc[:,:2]\n",
    "income[income.isna()] = 0\n",
    "income.rename(columns={'ZIPCODE':'destination', 'median_familyIncome(USD)' : 'income'}, inplace=True)\n",
    "income['income'] = income['income']/income['income'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the population jobs feature into the dataset\n",
    "\n",
    "jobs = pd.read_csv('data/zipcode_population_Jobs.csv', delimiter=',')\n",
    "jobs = jobs.iloc[:,:2]\n",
    "jobs.rename(columns={'ZIPCODE':'destination', 'totalJobs' : 'jobs'}, inplace=True)\n",
    "jobs['jobs'] = jobs['jobs'] / areas['area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the population feature into the dataset\n",
    "\n",
    "population = pd.read_csv('data/zipcode_population_Jobs.csv', delimiter=',')\n",
    "population = population[['ZIPCODE','POPULATION']]\n",
    "population.rename(columns={'ZIPCODE':'destination', 'POPULATION' : 'population'}, inplace=True)\n",
    "population['population'] = population['population'] / areas['area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(population)\n",
    "data = data.merge(jobs)\n",
    "data = data.merge(housePrice)\n",
    "data = data.merge(area)\n",
    "data = data.merge(income)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin</th>\n",
       "      <th>destination</th>\n",
       "      <th>weight</th>\n",
       "      <th>initialFeat</th>\n",
       "      <th>true_label</th>\n",
       "      <th>population</th>\n",
       "      <th>jobs</th>\n",
       "      <th>house_price</th>\n",
       "      <th>area</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11436</td>\n",
       "      <td>10009</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001283</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.001633</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.003724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11213</td>\n",
       "      <td>10009</td>\n",
       "      <td>14</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001283</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.001633</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.003724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11212</td>\n",
       "      <td>10009</td>\n",
       "      <td>27</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001283</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.001633</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.003724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11225</td>\n",
       "      <td>10009</td>\n",
       "      <td>26</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001283</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.001633</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.003724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11218</td>\n",
       "      <td>10009</td>\n",
       "      <td>60</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001283</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.001633</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.003724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36407</th>\n",
       "      <td>11211</td>\n",
       "      <td>11371</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003652</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36408</th>\n",
       "      <td>11373</td>\n",
       "      <td>11371</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003652</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36409</th>\n",
       "      <td>10168</td>\n",
       "      <td>11371</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003652</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36410</th>\n",
       "      <td>10278</td>\n",
       "      <td>11371</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003652</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36411</th>\n",
       "      <td>10036</td>\n",
       "      <td>11371</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003652</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36412 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       origin  destination  weight  initialFeat  true_label  population  \\\n",
       "0       11436        10009       1          4.0           4    0.001283   \n",
       "1       11213        10009      14          3.0           3    0.001283   \n",
       "2       11212        10009      27          3.0           3    0.001283   \n",
       "3       11225        10009      26          3.0           3    0.001283   \n",
       "4       11218        10009      60          3.0           3    0.001283   \n",
       "...       ...          ...     ...          ...         ...         ...   \n",
       "36407   11211        11371       7          1.0           3    0.000000   \n",
       "36408   11373        11371       3          4.0           4    0.000000   \n",
       "36409   10168        11371       1          1.0           1    0.000000   \n",
       "36410   10278        11371       1          1.0           1    0.000000   \n",
       "36411   10036        11371       5          1.0           1    0.000000   \n",
       "\n",
       "           jobs  house_price      area    income  \n",
       "0      0.000186     0.001633  0.001901  0.003724  \n",
       "1      0.000186     0.001633  0.001901  0.003724  \n",
       "2      0.000186     0.001633  0.001901  0.003724  \n",
       "3      0.000186     0.001633  0.001901  0.003724  \n",
       "4      0.000186     0.001633  0.001901  0.003724  \n",
       "...         ...          ...       ...       ...  \n",
       "36407  0.000486     0.000000  0.003652  0.000000  \n",
       "36408  0.000486     0.000000  0.003652  0.000000  \n",
       "36409  0.000486     0.000000  0.003652  0.000000  \n",
       "36410  0.000486     0.000000  0.003652  0.000000  \n",
       "36411  0.000486     0.000000  0.003652  0.000000  \n",
       "\n",
       "[36412 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set initial model config\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "weight_decay = 1e-8\n",
    "epochs = 10000\n",
    "seed = 635\n",
    "hidden = 16\n",
    "lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a symmetric normalization for the propogating the layer, i.e. $$D^{−1/2}AD^{−1/2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(adj):\n",
    "\n",
    "    adj = torch.FloatTensor(adj)\n",
    "    adj_id = torch.FloatTensor(torch.eye(adj.shape[1]))\n",
    "    adj_id = adj_id.reshape((1, adj.shape[1], adj.shape[1]))\n",
    "    adj_id = adj_id.repeat(adj.shape[0], 1, 1)\n",
    "    adj = adj + adj_id\n",
    "    rowsum = torch.FloatTensor(adj.sum(2))\n",
    "    degree_mat_inv_sqrt = torch.diag_embed(torch.float_power(rowsum,-0.5), dim1=-2, dim2=-1).float()\n",
    "    adj_norm = torch.bmm(torch.transpose(torch.bmm(adj,degree_mat_inv_sqrt),1,2),degree_mat_inv_sqrt)\n",
    "\n",
    "    return adj_norm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The activation function for the GNN is the double ReLU which is linear between between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doublerelu(x):\n",
    "    return torch.clamp(x, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Layer propogation rule of the GNN is : $$ H^{(l+1)} = f(H^{(l)}, A) = \\sigma ( H^{(l)}W_1^{(l)} + \\hat{D}^{-1/2}\\hat{A}\\hat{D}^{-1/2}H^{(l)}W_2^{(l)}) $$\n",
    "\n",
    "where H is the l'th neural network layer, A is the adjaceny matrix, D is the diagonal node degree matrix, W1 , W2 are learnable weight matrices initialised as W1 = 1, W2 = 0  and sigma is the activation function doublerelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN1Layer(Module):\n",
    "\n",
    "    def __init__(self, batch_size, in_features, out_features, first):\n",
    "        super(GNN1Layer, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # Initialse W1 = 1, W2 = 0 as pytorch learnable weights (parameters) that have require_grad = True which is\n",
    "        # required for calculating gradients while backpropogating using gradient descent\n",
    "        weight1_eye = torch.FloatTensor(torch.eye(in_features, out_features))\n",
    "        weight1_eye = weight1_eye.reshape((1, in_features, out_features))\n",
    "        weight1_eye = weight1_eye.repeat(batch_size, 1, 1)\n",
    "        self.weight1 = Parameter(weight1_eye)\n",
    "        if not first:\n",
    "            self.weight2 = Parameter(torch.zeros(batch_size, in_features, out_features))\n",
    "        else:\n",
    "            self.weight2 = Parameter(torch.empty(batch_size, in_features, out_features))\n",
    "            nn.init.kaiming_normal_(self.weight2, mode='fan_out')\n",
    "\n",
    "    def forward(self, input, adj):\n",
    "        # first term H*W1\n",
    "        v1 = torch.bmm(input, self.weight1)\n",
    "        # second term adj_norm*H*W2\n",
    "        v2 = torch.bmm(torch.bmm(adj, input), self.weight2)\n",
    "        # adding the two terms\n",
    "        output = v1 + v2\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN1(nn.Module):\n",
    "\n",
    "    def __init__(self, batch_size, nfeat, ndim, hidden, first):\n",
    "        super(GNN1, self).__init__()\n",
    "\n",
    "        self.gc1 = GNN1Layer(batch_size, nfeat, hidden, first)\n",
    "        self.gc2 = GNN1Layer(batch_size, hidden, ndim, first)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "\n",
    "        # Applying activation function sigma (doublerelu) on the layer propogation\n",
    "        x = doublerelu(self.gc1(x, adj))\n",
    "        x = doublerelu(self.gc2(x, adj))\n",
    "        x = x/x.sum(axis=2).unsqueeze(2) #normalize st sum = 1\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(adj,features,labels,train_indices,val_indices,first=False):\n",
    "    \n",
    "    # calculate symmetric normalisation for layer propogation\n",
    "    adj_norm = normalize(adj)\n",
    "    \n",
    "    labels = labels - 1\n",
    "    \n",
    "    # Convert from numpy to torch tensors\n",
    "    adj = torch.FloatTensor(adj)\n",
    "    adj_norm = torch.FloatTensor(adj_norm)\n",
    "    features = torch.FloatTensor(features)\n",
    "    labels = torch.FloatTensor(labels)\n",
    "    \n",
    "    # initialise the model\n",
    "    model = GNN1(batch_size=adj.shape[0],\n",
    "                nfeat=features.shape[-1],\n",
    "                ndim=nb_label,\n",
    "                hidden=hidden,\n",
    "                first=first)\n",
    "    \n",
    "    # Transfer the weights to GPU for training\n",
    "    if cuda:\n",
    "        model.cuda()\n",
    "        features = features.cuda()\n",
    "        adj = adj.cuda()\n",
    "        adj_norm = adj_norm.cuda()\n",
    "        labels = labels.cuda()\n",
    "    \n",
    "    # Train model\n",
    "    t_total = time.time()\n",
    "\n",
    "    # Using adam optimizers for backpropogation\n",
    "    optimizer = optim.Adam(model.parameters(),\n",
    "                           lr=lr, weight_decay=weight_decay)\n",
    "    \n",
    "    # loss function criteria is cross entropy loss\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Train for the no of epochs\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        t = time.time()\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        # Pytorch accumulates gradient after every operation on tensors (defined by the model architecture)\n",
    "        # with require_grad = True. With each new epoch, we need to reset this gradient to 0 to calculate gradient\n",
    "        # for this epoch.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # get the output from forward propogation of our model\n",
    "        output = model(features, adj_norm)\n",
    "        \n",
    "        # Calculate Train accuracy\n",
    "        train_output = output[:,train_indices,:]\n",
    "        train_labels = labels[train_indices,:]\n",
    "        train_accuracy = torch.sum(torch.argmax(train_output,axis=2)==train_labels.reshape(1,-1))/train_labels.shape[0]\n",
    "        \n",
    "        # Calculate the loss between our models training output and true label\n",
    "        loss = criterion(output[0],labels.reshape(-1).long())\n",
    "        \n",
    "        # Calculate the gradients \n",
    "        loss.backward(retain_graph=True)\n",
    "\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        # Calculate Validation accuracy\n",
    "        with torch.no_grad():\n",
    "            val_output = output[:,val_indices,:]\n",
    "            val_labels = labels[val_indices,:]\n",
    "            val_accuracy = torch.sum(torch.argmax(val_output,axis=2)==val_labels.reshape(1,-1))/val_labels.shape[0]\n",
    "\n",
    "        # Print summary of training \n",
    "        if epoch == 0:\n",
    "            best_loss = loss\n",
    "            best_output = output\n",
    "            best_acc = train_accuracy\n",
    "            best_val_acc = val_accuracy\n",
    "            best_val_output = val_output\n",
    "        else:\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "                best_output = output\n",
    "                best_acc = train_accuracy\n",
    "                best_val_acc = val_accuracy\n",
    "                best_val_output = val_output\n",
    "\n",
    "        if epoch == 0 or (epoch+1) % 1000 == 0:\n",
    "            print('Epoch: {:04d}'.format(epoch + 1),\n",
    "                  'Train Accuracy: {:.4f}'.format(best_acc.item()),\n",
    "                  'Validation Accuracy: {:.4f}'.format(best_val_acc.item()),\n",
    "                  'Loss: {:.8f}'.format(best_loss.item()),\n",
    "                  'time: {:.4f}s'.format(time.time() - t))\n",
    "            \n",
    "    print(\"Optimization Finished!\")\n",
    "    print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
    "    \n",
    "    return best_loss,best_output#,best_val_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svdApprox(adj, dim, relu=False):\n",
    "    adj = torch.FloatTensor(adj[0])\n",
    "    U, S, Vh = torch.linalg.svd(adj)\n",
    "    mu = torch.matmul(torch.matmul(U[:, :dim], torch.diag(S[:dim])), Vh[:dim, :])\n",
    "\n",
    "    embedx = torch.matmul(U[:, :dim], torch.diag(torch.pow(S[:dim], 0.5)))\n",
    "    embedy = torch.transpose(torch.matmul(torch.diag(torch.pow(S[:dim], 0.5)), Vh[:dim, :]), 0, 1)\n",
    "\n",
    "    return embedx, embedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for loading data, returns adjacency matrix, initial feature assignments and true labels\n",
    "\n",
    "def load_data():\n",
    "\n",
    "    G = nx.from_pandas_edgelist(data, 'origin', 'destination', 'weight',create_using=nx.DiGraph())\n",
    "    adj_list = np.array([nx.adjacency_matrix(G).todense()], dtype=float)\n",
    "    \n",
    "    init_feat1 = np.array(data.groupby('origin')['population'].agg(['unique']))\n",
    "    init_feat1 = np.array(list(map(lambda x: x[0][0], init_feat1))).reshape(-1, 1)\n",
    "    init_feat2 = np.array(data.groupby('origin')['house_price'].agg(['unique']))\n",
    "    init_feat2 = np.array(list(map(lambda x: x[0][0], init_feat2))).reshape(-1, 1)\n",
    "    init_feat3 = np.array(data.groupby('origin')['area'].agg(['unique']))\n",
    "    init_feat3 = np.array(list(map(lambda x: x[0][0], init_feat3))).reshape(-1, 1)\n",
    "    init_feat4 = np.array(data.groupby('origin')['income'].agg(['unique']))\n",
    "    init_feat4 = np.array(list(map(lambda x: x[0][0], init_feat4))).reshape(-1, 1)\n",
    "    init_feat5 = np.array(data.groupby('origin')['jobs'].agg(['unique']))\n",
    "    init_feat5 = np.array(list(map(lambda x: x[0][0], init_feat5))).reshape(-1, 1)\n",
    "    \n",
    "    init_feat = np.concatenate([init_feat1,init_feat2,init_feat3,init_feat4,init_feat5],axis=1)\n",
    "    \n",
    "    true_label = np.array(data.groupby('origin')['true_label'].agg(['unique']))\n",
    "    \n",
    "    true_label = np.array(list(map(lambda x: x[0][0], true_label))).reshape(-1, 1)\n",
    "    return adj_list,init_feat,true_label\n",
    "\n",
    "adj,feature,labels = load_data()\n",
    "\n",
    "features = np.expand_dims(feature, axis=0)\n",
    "val_features = np.copy(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_feat = np.array(data.groupby('origin')['initialFeat'].agg(['unique']))\n",
    "init_feat = np.array(list(map(lambda x: x[0][0], init_feat))).reshape(-1, 1)\n",
    "init_feat = init_feat - 1\n",
    "nb_label = int(max(init_feat)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 Train Accuracy: 0.2349 Validation Accuracy: 0.2143 Loss: 1.65001917 time: 1.2470s\n",
      "Epoch: 1000 Train Accuracy: 0.3373 Validation Accuracy: 0.1905 Loss: 1.57184029 time: 0.0020s\n",
      "Epoch: 2000 Train Accuracy: 0.3434 Validation Accuracy: 0.1905 Loss: 1.56878984 time: 0.0020s\n",
      "Epoch: 3000 Train Accuracy: 0.3494 Validation Accuracy: 0.1905 Loss: 1.56440806 time: 0.0030s\n",
      "Epoch: 4000 Train Accuracy: 0.3494 Validation Accuracy: 0.1905 Loss: 1.55421174 time: 0.0020s\n",
      "Epoch: 5000 Train Accuracy: 0.3494 Validation Accuracy: 0.1905 Loss: 1.55066764 time: 0.0020s\n",
      "Epoch: 6000 Train Accuracy: 0.3434 Validation Accuracy: 0.2619 Loss: 1.54892099 time: 0.0030s\n",
      "Epoch: 7000 Train Accuracy: 0.3434 Validation Accuracy: 0.2619 Loss: 1.54892099 time: 0.0020s\n",
      "Epoch: 8000 Train Accuracy: 0.3434 Validation Accuracy: 0.2619 Loss: 1.54892099 time: 0.0020s\n",
      "Epoch: 9000 Train Accuracy: 0.3434 Validation Accuracy: 0.2619 Loss: 1.54892099 time: 0.0020s\n",
      "Epoch: 10000 Train Accuracy: 0.3434 Validation Accuracy: 0.2619 Loss: 1.54892099 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 23.7966s\n",
      "Epoch: 0001 Train Accuracy: 0.3434 Validation Accuracy: 0.2619 Loss: 1.54892111 time: 0.0040s\n",
      "Epoch: 1000 Train Accuracy: 0.5241 Validation Accuracy: 0.5476 Loss: 1.36015153 time: 0.0030s\n",
      "Epoch: 2000 Train Accuracy: 0.6084 Validation Accuracy: 0.6190 Loss: 1.31656384 time: 0.0030s\n",
      "Epoch: 3000 Train Accuracy: 0.6024 Validation Accuracy: 0.6429 Loss: 1.28176177 time: 0.0030s\n",
      "Epoch: 4000 Train Accuracy: 0.5904 Validation Accuracy: 0.6429 Loss: 1.27190757 time: 0.0024s\n",
      "Epoch: 5000 Train Accuracy: 0.6024 Validation Accuracy: 0.6429 Loss: 1.26721835 time: 0.0030s\n",
      "Epoch: 6000 Train Accuracy: 0.6265 Validation Accuracy: 0.6667 Loss: 1.25635481 time: 0.0030s\n",
      "Epoch: 7000 Train Accuracy: 0.6265 Validation Accuracy: 0.6667 Loss: 1.25635481 time: 0.0020s\n",
      "Epoch: 8000 Train Accuracy: 0.6386 Validation Accuracy: 0.6667 Loss: 1.25014639 time: 0.0020s\n",
      "Epoch: 9000 Train Accuracy: 0.6386 Validation Accuracy: 0.6667 Loss: 1.24894404 time: 0.0020s\n",
      "Epoch: 10000 Train Accuracy: 0.6386 Validation Accuracy: 0.6667 Loss: 1.24894404 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 22.9092s\n",
      "Epoch: 0001 Train Accuracy: 0.6386 Validation Accuracy: 0.6667 Loss: 1.24894404 time: 0.0030s\n",
      "Epoch: 1000 Train Accuracy: 0.6386 Validation Accuracy: 0.6667 Loss: 1.24451709 time: 0.0020s\n",
      "Epoch: 2000 Train Accuracy: 0.6506 Validation Accuracy: 0.6905 Loss: 1.23948801 time: 0.0030s\n",
      "Epoch: 3000 Train Accuracy: 0.6566 Validation Accuracy: 0.6905 Loss: 1.22721148 time: 0.0030s\n",
      "Epoch: 4000 Train Accuracy: 0.6506 Validation Accuracy: 0.6905 Loss: 1.22068238 time: 0.0030s\n",
      "Epoch: 5000 Train Accuracy: 0.6627 Validation Accuracy: 0.6905 Loss: 1.21565139 time: 0.0030s\n",
      "Epoch: 6000 Train Accuracy: 0.6627 Validation Accuracy: 0.6905 Loss: 1.21565139 time: 0.0030s\n",
      "Epoch: 7000 Train Accuracy: 0.6627 Validation Accuracy: 0.6905 Loss: 1.21565139 time: 0.0030s\n",
      "Epoch: 8000 Train Accuracy: 0.6627 Validation Accuracy: 0.6905 Loss: 1.21565139 time: 0.0020s\n",
      "Epoch: 9000 Train Accuracy: 0.6627 Validation Accuracy: 0.6905 Loss: 1.21565139 time: 0.0020s\n",
      "Epoch: 10000 Train Accuracy: 0.6627 Validation Accuracy: 0.6905 Loss: 1.21565139 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 22.7977s\n",
      "Epoch: 0001 Train Accuracy: 0.6627 Validation Accuracy: 0.6905 Loss: 1.21565139 time: 0.0030s\n",
      "Epoch: 1000 Train Accuracy: 0.6687 Validation Accuracy: 0.7143 Loss: 1.21331871 time: 0.0020s\n",
      "Epoch: 2000 Train Accuracy: 0.6687 Validation Accuracy: 0.7381 Loss: 1.21049237 time: 0.0030s\n",
      "Epoch: 3000 Train Accuracy: 0.6747 Validation Accuracy: 0.7381 Loss: 1.20695555 time: 0.0030s\n",
      "Epoch: 4000 Train Accuracy: 0.6867 Validation Accuracy: 0.7619 Loss: 1.20250380 time: 0.0020s\n",
      "Epoch: 5000 Train Accuracy: 0.6928 Validation Accuracy: 0.7619 Loss: 1.19572818 time: 0.0030s\n",
      "Epoch: 6000 Train Accuracy: 0.6867 Validation Accuracy: 0.7619 Loss: 1.19198298 time: 0.0020s\n",
      "Epoch: 7000 Train Accuracy: 0.6988 Validation Accuracy: 0.7381 Loss: 1.19193947 time: 0.0030s\n",
      "Epoch: 8000 Train Accuracy: 0.7048 Validation Accuracy: 0.7381 Loss: 1.19042408 time: 0.0020s\n",
      "Epoch: 9000 Train Accuracy: 0.7048 Validation Accuracy: 0.7381 Loss: 1.19042408 time: 0.0020s\n",
      "Epoch: 10000 Train Accuracy: 0.7048 Validation Accuracy: 0.7381 Loss: 1.19042408 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 22.8015s\n",
      "Epoch: 0001 Train Accuracy: 0.7048 Validation Accuracy: 0.7381 Loss: 1.19042408 time: 0.0030s\n",
      "Epoch: 1000 Train Accuracy: 0.6988 Validation Accuracy: 0.7381 Loss: 1.18849409 time: 0.0030s\n",
      "Epoch: 2000 Train Accuracy: 0.7169 Validation Accuracy: 0.7381 Loss: 1.18626285 time: 0.0030s\n",
      "Epoch: 3000 Train Accuracy: 0.7108 Validation Accuracy: 0.7143 Loss: 1.18365467 time: 0.0020s\n",
      "Epoch: 4000 Train Accuracy: 0.7169 Validation Accuracy: 0.7143 Loss: 1.18168151 time: 0.0030s\n",
      "Epoch: 5000 Train Accuracy: 0.7169 Validation Accuracy: 0.7143 Loss: 1.17959583 time: 0.0020s\n",
      "Epoch: 6000 Train Accuracy: 0.7169 Validation Accuracy: 0.7143 Loss: 1.17959583 time: 0.0030s\n",
      "Epoch: 7000 Train Accuracy: 0.7169 Validation Accuracy: 0.7143 Loss: 1.17959583 time: 0.0020s\n",
      "Epoch: 8000 Train Accuracy: 0.7169 Validation Accuracy: 0.7143 Loss: 1.17959583 time: 0.0030s\n",
      "Epoch: 9000 Train Accuracy: 0.7169 Validation Accuracy: 0.7143 Loss: 1.17959583 time: 0.0020s\n",
      "Epoch: 10000 Train Accuracy: 0.7169 Validation Accuracy: 0.7143 Loss: 1.17959583 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 23.1340s\n",
      "Epoch: 0001 Train Accuracy: 0.7169 Validation Accuracy: 0.7143 Loss: 1.17959583 time: 0.0020s\n",
      "Epoch: 1000 Train Accuracy: 0.7169 Validation Accuracy: 0.7143 Loss: 1.17868125 time: 0.0030s\n",
      "Epoch: 2000 Train Accuracy: 0.7229 Validation Accuracy: 0.7143 Loss: 1.17697060 time: 0.0020s\n",
      "Epoch: 3000 Train Accuracy: 0.7289 Validation Accuracy: 0.7143 Loss: 1.17589426 time: 0.0020s\n",
      "Epoch: 4000 Train Accuracy: 0.7289 Validation Accuracy: 0.7143 Loss: 1.17589426 time: 0.0030s\n",
      "Epoch: 5000 Train Accuracy: 0.7289 Validation Accuracy: 0.7143 Loss: 1.17589426 time: 0.0030s\n",
      "Epoch: 6000 Train Accuracy: 0.7289 Validation Accuracy: 0.7143 Loss: 1.17589426 time: 0.0020s\n",
      "Epoch: 7000 Train Accuracy: 0.7289 Validation Accuracy: 0.7143 Loss: 1.17589426 time: 0.0020s\n",
      "Epoch: 8000 Train Accuracy: 0.7289 Validation Accuracy: 0.7143 Loss: 1.17589426 time: 0.0030s\n",
      "Epoch: 9000 Train Accuracy: 0.7289 Validation Accuracy: 0.7143 Loss: 1.17589426 time: 0.0030s\n",
      "Epoch: 10000 Train Accuracy: 0.7289 Validation Accuracy: 0.7143 Loss: 1.17589426 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 23.2473s\n",
      "Epoch: 0001 Train Accuracy: 0.7289 Validation Accuracy: 0.7143 Loss: 1.17589426 time: 0.0030s\n",
      "Epoch: 1000 Train Accuracy: 0.7289 Validation Accuracy: 0.7143 Loss: 1.17479205 time: 0.0030s\n",
      "Epoch: 2000 Train Accuracy: 0.7229 Validation Accuracy: 0.7143 Loss: 1.17363846 time: 0.0030s\n",
      "Epoch: 3000 Train Accuracy: 0.7289 Validation Accuracy: 0.7143 Loss: 1.17095482 time: 0.0020s\n",
      "Epoch: 4000 Train Accuracy: 0.7349 Validation Accuracy: 0.6667 Loss: 1.16696954 time: 0.0020s\n",
      "Epoch: 5000 Train Accuracy: 0.7349 Validation Accuracy: 0.6667 Loss: 1.16696954 time: 0.0020s\n",
      "Epoch: 6000 Train Accuracy: 0.7349 Validation Accuracy: 0.6667 Loss: 1.16696954 time: 0.0020s\n",
      "Epoch: 7000 Train Accuracy: 0.7349 Validation Accuracy: 0.6667 Loss: 1.16696954 time: 0.0020s\n",
      "Epoch: 8000 Train Accuracy: 0.7349 Validation Accuracy: 0.6667 Loss: 1.16696954 time: 0.0027s\n",
      "Epoch: 9000 Train Accuracy: 0.7349 Validation Accuracy: 0.6667 Loss: 1.16696954 time: 0.0030s\n",
      "Epoch: 10000 Train Accuracy: 0.7349 Validation Accuracy: 0.6667 Loss: 1.16696954 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 22.7396s\n",
      "Epoch: 0001 Train Accuracy: 0.7349 Validation Accuracy: 0.6667 Loss: 1.16696954 time: 0.0030s\n",
      "Epoch: 1000 Train Accuracy: 0.7410 Validation Accuracy: 0.6667 Loss: 1.16568172 time: 0.0030s\n",
      "Epoch: 2000 Train Accuracy: 0.7410 Validation Accuracy: 0.6667 Loss: 1.16341698 time: 0.0025s\n",
      "Epoch: 3000 Train Accuracy: 0.7590 Validation Accuracy: 0.6667 Loss: 1.15818357 time: 0.0030s\n",
      "Epoch: 4000 Train Accuracy: 0.7590 Validation Accuracy: 0.6905 Loss: 1.15497220 time: 0.0020s\n",
      "Epoch: 5000 Train Accuracy: 0.7590 Validation Accuracy: 0.6905 Loss: 1.15497220 time: 0.0020s\n",
      "Epoch: 6000 Train Accuracy: 0.7590 Validation Accuracy: 0.6905 Loss: 1.15497220 time: 0.0020s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7000 Train Accuracy: 0.7590 Validation Accuracy: 0.6905 Loss: 1.15497220 time: 0.0030s\n",
      "Epoch: 8000 Train Accuracy: 0.7590 Validation Accuracy: 0.6905 Loss: 1.15497220 time: 0.0030s\n",
      "Epoch: 9000 Train Accuracy: 0.7590 Validation Accuracy: 0.6905 Loss: 1.15497220 time: 0.0020s\n",
      "Epoch: 10000 Train Accuracy: 0.7590 Validation Accuracy: 0.6905 Loss: 1.15497220 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 22.1449s\n",
      "Epoch: 0001 Train Accuracy: 0.7590 Validation Accuracy: 0.6905 Loss: 1.15497220 time: 0.0030s\n",
      "Epoch: 1000 Train Accuracy: 0.7590 Validation Accuracy: 0.6905 Loss: 1.15260100 time: 0.0030s\n",
      "Epoch: 2000 Train Accuracy: 0.7590 Validation Accuracy: 0.6905 Loss: 1.15063953 time: 0.0030s\n",
      "Epoch: 3000 Train Accuracy: 0.7590 Validation Accuracy: 0.6905 Loss: 1.14674771 time: 0.0020s\n",
      "Epoch: 4000 Train Accuracy: 0.7711 Validation Accuracy: 0.6905 Loss: 1.14416325 time: 0.0020s\n",
      "Epoch: 5000 Train Accuracy: 0.7711 Validation Accuracy: 0.6905 Loss: 1.14416325 time: 0.0020s\n",
      "Epoch: 6000 Train Accuracy: 0.7711 Validation Accuracy: 0.6905 Loss: 1.14416325 time: 0.0020s\n",
      "Epoch: 7000 Train Accuracy: 0.7711 Validation Accuracy: 0.6905 Loss: 1.14416325 time: 0.0029s\n",
      "Epoch: 8000 Train Accuracy: 0.7711 Validation Accuracy: 0.6905 Loss: 1.14416325 time: 0.0026s\n",
      "Epoch: 9000 Train Accuracy: 0.7711 Validation Accuracy: 0.6905 Loss: 1.14416325 time: 0.0020s\n",
      "Epoch: 10000 Train Accuracy: 0.7711 Validation Accuracy: 0.6905 Loss: 1.14416325 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 22.4487s\n",
      "Epoch: 0001 Train Accuracy: 0.7711 Validation Accuracy: 0.6905 Loss: 1.14416325 time: 0.0020s\n",
      "Epoch: 1000 Train Accuracy: 0.7711 Validation Accuracy: 0.6905 Loss: 1.14295709 time: 0.0040s\n",
      "Epoch: 2000 Train Accuracy: 0.7711 Validation Accuracy: 0.6905 Loss: 1.14182830 time: 0.0030s\n",
      "Epoch: 3000 Train Accuracy: 0.7771 Validation Accuracy: 0.6905 Loss: 1.14123130 time: 0.0030s\n",
      "Epoch: 4000 Train Accuracy: 0.7771 Validation Accuracy: 0.6905 Loss: 1.14123130 time: 0.0030s\n",
      "Epoch: 5000 Train Accuracy: 0.7771 Validation Accuracy: 0.6905 Loss: 1.14123130 time: 0.0020s\n",
      "Epoch: 6000 Train Accuracy: 0.7771 Validation Accuracy: 0.6905 Loss: 1.14123130 time: 0.0020s\n",
      "Epoch: 7000 Train Accuracy: 0.7771 Validation Accuracy: 0.6905 Loss: 1.14123130 time: 0.0020s\n",
      "Epoch: 8000 Train Accuracy: 0.7771 Validation Accuracy: 0.6905 Loss: 1.14123130 time: 0.0030s\n",
      "Epoch: 9000 Train Accuracy: 0.7771 Validation Accuracy: 0.6905 Loss: 1.14123130 time: 0.0020s\n",
      "Epoch: 10000 Train Accuracy: 0.7771 Validation Accuracy: 0.6905 Loss: 1.14123130 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 22.9386s\n",
      "Epoch: 0001 Train Accuracy: 0.7771 Validation Accuracy: 0.6905 Loss: 1.14123130 time: 0.0020s\n",
      "Epoch: 1000 Train Accuracy: 0.7771 Validation Accuracy: 0.6905 Loss: 1.14069796 time: 0.0030s\n",
      "Epoch: 2000 Train Accuracy: 0.7831 Validation Accuracy: 0.6905 Loss: 1.14014804 time: 0.0030s\n",
      "Epoch: 3000 Train Accuracy: 0.7831 Validation Accuracy: 0.6905 Loss: 1.13832510 time: 0.0030s\n",
      "Epoch: 4000 Train Accuracy: 0.7952 Validation Accuracy: 0.6905 Loss: 1.12987685 time: 0.0030s\n",
      "Epoch: 5000 Train Accuracy: 0.7952 Validation Accuracy: 0.6905 Loss: 1.12987685 time: 0.0020s\n",
      "Epoch: 6000 Train Accuracy: 0.7952 Validation Accuracy: 0.6905 Loss: 1.12987685 time: 0.0020s\n",
      "Epoch: 7000 Train Accuracy: 0.7952 Validation Accuracy: 0.6905 Loss: 1.12987685 time: 0.0020s\n",
      "Epoch: 8000 Train Accuracy: 0.7952 Validation Accuracy: 0.6905 Loss: 1.12987685 time: 0.0030s\n",
      "Epoch: 9000 Train Accuracy: 0.7952 Validation Accuracy: 0.6905 Loss: 1.12987685 time: 0.0030s\n",
      "Epoch: 10000 Train Accuracy: 0.7952 Validation Accuracy: 0.6905 Loss: 1.12987685 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 22.5253s\n",
      "Epoch: 0001 Train Accuracy: 0.7952 Validation Accuracy: 0.6905 Loss: 1.12987685 time: 0.0030s\n",
      "Epoch: 1000 Train Accuracy: 0.7952 Validation Accuracy: 0.6905 Loss: 1.12906969 time: 0.0020s\n",
      "Epoch: 2000 Train Accuracy: 0.7952 Validation Accuracy: 0.6905 Loss: 1.12839139 time: 0.0030s\n",
      "Epoch: 3000 Train Accuracy: 0.7952 Validation Accuracy: 0.6905 Loss: 1.12714243 time: 0.0020s\n",
      "Epoch: 4000 Train Accuracy: 0.7892 Validation Accuracy: 0.7381 Loss: 1.12535906 time: 0.0030s\n",
      "Epoch: 5000 Train Accuracy: 0.7892 Validation Accuracy: 0.7381 Loss: 1.12382829 time: 0.0030s\n",
      "Epoch: 6000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.12051117 time: 0.0020s\n",
      "Epoch: 7000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11932743 time: 0.0020s\n",
      "Epoch: 8000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11932743 time: 0.0022s\n",
      "Epoch: 9000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11932743 time: 0.0020s\n",
      "Epoch: 10000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11932743 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 23.3378s\n",
      "Epoch: 0001 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11932743 time: 0.0020s\n",
      "Epoch: 1000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11818016 time: 0.0020s\n",
      "Epoch: 2000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11693573 time: 0.0020s\n",
      "Epoch: 3000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11596751 time: 0.0030s\n",
      "Epoch: 4000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11584449 time: 0.0020s\n",
      "Epoch: 5000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11565351 time: 0.0030s\n",
      "Epoch: 6000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11531174 time: 0.0030s\n",
      "Epoch: 7000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11516237 time: 0.0030s\n",
      "Epoch: 8000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11516237 time: 0.0030s\n",
      "Epoch: 9000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11516237 time: 0.0030s\n",
      "Epoch: 10000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11516237 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 22.8208s\n",
      "Epoch: 0001 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11516237 time: 0.0030s\n",
      "Epoch: 1000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11513197 time: 0.0020s\n",
      "Epoch: 2000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11511338 time: 0.0030s\n",
      "Epoch: 3000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11510575 time: 0.0020s\n",
      "Epoch: 4000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11509824 time: 0.0027s\n",
      "Epoch: 5000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11506510 time: 0.0030s\n",
      "Epoch: 6000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11504853 time: 0.0030s\n",
      "Epoch: 7000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11503732 time: 0.0030s\n",
      "Epoch: 8000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11502695 time: 0.0020s\n",
      "Epoch: 9000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11501563 time: 0.0020s\n",
      "Epoch: 10000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11500406 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 23.1908s\n",
      "Epoch: 0001 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11500406 time: 0.0030s\n",
      "Epoch: 1000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11499107 time: 0.0028s\n",
      "Epoch: 2000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11499012 time: 0.0020s\n",
      "Epoch: 3000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11498904 time: 0.0030s\n",
      "Epoch: 4000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11498761 time: 0.0020s\n",
      "Epoch: 5000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11498594 time: 0.0020s\n",
      "Epoch: 6000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11498356 time: 0.0030s\n",
      "Epoch: 7000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11498058 time: 0.0022s\n",
      "Epoch: 8000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11497712 time: 0.0030s\n",
      "Epoch: 9000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11497200 time: 0.0030s\n",
      "Epoch: 10000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11496425 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 22.9435s\n",
      "Epoch: 0001 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11496425 time: 0.0020s\n",
      "Epoch: 1000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11496377 time: 0.0020s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11496329 time: 0.0030s\n",
      "Epoch: 3000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11496222 time: 0.0030s\n",
      "Epoch: 4000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11496067 time: 0.0030s\n",
      "Epoch: 5000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11495852 time: 0.0030s\n",
      "Epoch: 6000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11495543 time: 0.0020s\n",
      "Epoch: 7000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11495042 time: 0.0020s\n",
      "Epoch: 8000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11494148 time: 0.0020s\n",
      "Epoch: 9000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11490214 time: 0.0030s\n",
      "Epoch: 10000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11482573 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 22.5562s\n",
      "Epoch: 0001 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11482573 time: 0.0030s\n",
      "Epoch: 1000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11482537 time: 0.0030s\n",
      "Epoch: 2000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11482489 time: 0.0020s\n",
      "Epoch: 3000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11482406 time: 0.0020s\n",
      "Epoch: 4000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11482275 time: 0.0020s\n",
      "Epoch: 5000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11482096 time: 0.0020s\n",
      "Epoch: 6000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11481833 time: 0.0020s\n",
      "Epoch: 7000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11481404 time: 0.0030s\n",
      "Epoch: 8000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11480606 time: 0.0020s\n",
      "Epoch: 9000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11477804 time: 0.0030s\n",
      "Epoch: 10000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11473536 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 22.1025s\n",
      "Epoch: 0001 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11473536 time: 0.0030s\n",
      "Epoch: 1000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11473417 time: 0.0030s\n",
      "Epoch: 2000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11473382 time: 0.0030s\n",
      "Epoch: 3000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11473298 time: 0.0030s\n",
      "Epoch: 4000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11473215 time: 0.0020s\n",
      "Epoch: 5000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11473072 time: 0.0020s\n",
      "Epoch: 6000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11472881 time: 0.0030s\n",
      "Epoch: 7000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11472607 time: 0.0030s\n",
      "Epoch: 8000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11472213 time: 0.0020s\n",
      "Epoch: 9000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11471474 time: 0.0030s\n",
      "Epoch: 10000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11468935 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 23.0341s\n",
      "Epoch: 0001 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11468935 time: 0.0030s\n",
      "Epoch: 1000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11468923 time: 0.0030s\n",
      "Epoch: 2000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11468887 time: 0.0020s\n",
      "Epoch: 3000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11468828 time: 0.0030s\n",
      "Epoch: 4000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11468744 time: 0.0020s\n",
      "Epoch: 5000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11468625 time: 0.0020s\n",
      "Epoch: 6000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11468482 time: 0.0020s\n",
      "Epoch: 7000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11468267 time: 0.0020s\n",
      "Epoch: 8000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11467957 time: 0.0030s\n",
      "Epoch: 9000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11467493 time: 0.0020s\n",
      "Epoch: 10000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11466372 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 23.3001s\n",
      "Epoch: 0001 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11466372 time: 0.0030s\n",
      "Epoch: 1000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11466360 time: 0.0030s\n",
      "Epoch: 2000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11463618 time: 0.0030s\n",
      "Epoch: 3000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11450851 time: 0.0030s\n",
      "Epoch: 4000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11367834 time: 0.0030s\n",
      "Epoch: 5000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11367834 time: 0.0030s\n",
      "Epoch: 6000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11367834 time: 0.0020s\n",
      "Epoch: 7000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11367834 time: 0.0020s\n",
      "Epoch: 8000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11367834 time: 0.0030s\n",
      "Epoch: 9000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11367834 time: 0.0020s\n",
      "Epoch: 10000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11367834 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 22.5660s\n",
      "Epoch: 0001 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11367834 time: 0.0030s\n",
      "Epoch: 1000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11321855 time: 0.0020s\n",
      "Epoch: 2000 Train Accuracy: 0.8072 Validation Accuracy: 0.7143 Loss: 1.11209106 time: 0.0020s\n",
      "Epoch: 3000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.11125505 time: 0.0020s\n",
      "Epoch: 4000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.11125505 time: 0.0030s\n",
      "Epoch: 5000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.11125505 time: 0.0030s\n",
      "Epoch: 6000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.11125505 time: 0.0030s\n",
      "Epoch: 7000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.11125505 time: 0.0020s\n",
      "Epoch: 8000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.11125505 time: 0.0030s\n",
      "Epoch: 9000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.11125505 time: 0.0020s\n",
      "Epoch: 10000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.11125505 time: 0.0031s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 22.9932s\n",
      "Epoch: 0001 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.11125505 time: 0.0030s\n",
      "Epoch: 1000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.11015689 time: 0.0020s\n",
      "Epoch: 2000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10954940 time: 0.0020s\n",
      "Epoch: 3000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10950482 time: 0.0030s\n",
      "Epoch: 4000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10945034 time: 0.0020s\n",
      "Epoch: 5000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10938323 time: 0.0030s\n",
      "Epoch: 6000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10930324 time: 0.0030s\n",
      "Epoch: 7000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10921371 time: 0.0030s\n",
      "Epoch: 8000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10910559 time: 0.0030s\n",
      "Epoch: 9000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10896420 time: 0.0030s\n",
      "Epoch: 10000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10877156 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 23.0358s\n",
      "Epoch: 0001 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10877156 time: 0.0030s\n",
      "Epoch: 1000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10875022 time: 0.0030s\n",
      "Epoch: 2000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10874665 time: 0.0020s\n",
      "Epoch: 3000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10874057 time: 0.0020s\n",
      "Epoch: 4000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10873139 time: 0.0030s\n",
      "Epoch: 5000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10871744 time: 0.0030s\n",
      "Epoch: 6000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10869765 time: 0.0030s\n",
      "Epoch: 7000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10867262 time: 0.0030s\n",
      "Epoch: 8000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10865033 time: 0.0030s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10863864 time: 0.0030s\n",
      "Epoch: 10000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10863507 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 23.3163s\n",
      "Epoch: 0001 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10863507 time: 0.0030s\n",
      "Epoch: 1000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10863507 time: 0.0020s\n",
      "Epoch: 2000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10863495 time: 0.0020s\n",
      "Epoch: 3000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10863471 time: 0.0020s\n",
      "Epoch: 4000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10863435 time: 0.0020s\n",
      "Epoch: 5000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10863400 time: 0.0020s\n",
      "Epoch: 6000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10863352 time: 0.0030s\n",
      "Epoch: 7000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10863292 time: 0.0030s\n",
      "Epoch: 8000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10863233 time: 0.0030s\n",
      "Epoch: 9000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10863161 time: 0.0020s\n",
      "Epoch: 10000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10863101 time: 0.0026s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 22.9576s\n",
      "Epoch: 0001 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10863101 time: 0.0030s\n",
      "Epoch: 1000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10863101 time: 0.0030s\n",
      "Epoch: 2000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10863101 time: 0.0020s\n",
      "Epoch: 3000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10863090 time: 0.0040s\n",
      "Epoch: 4000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10863078 time: 0.0020s\n",
      "Epoch: 5000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10863042 time: 0.0020s\n",
      "Epoch: 6000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10863030 time: 0.0020s\n",
      "Epoch: 7000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862994 time: 0.0020s\n",
      "Epoch: 8000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862958 time: 0.0020s\n",
      "Epoch: 9000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862911 time: 0.0020s\n",
      "Epoch: 10000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862887 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 22.7049s\n",
      "Epoch: 0001 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862887 time: 0.0030s\n",
      "Epoch: 1000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862887 time: 0.0030s\n",
      "Epoch: 2000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862887 time: 0.0030s\n",
      "Epoch: 3000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862875 time: 0.0020s\n",
      "Epoch: 4000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862863 time: 0.0030s\n",
      "Epoch: 5000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862851 time: 0.0030s\n",
      "Epoch: 6000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862839 time: 0.0020s\n",
      "Epoch: 7000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862815 time: 0.0020s\n",
      "Epoch: 8000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862780 time: 0.0030s\n",
      "Epoch: 9000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862756 time: 0.0020s\n",
      "Epoch: 10000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862732 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 21.9915s\n",
      "Epoch: 0001 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862732 time: 0.0030s\n",
      "Epoch: 1000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862732 time: 0.0030s\n",
      "Epoch: 2000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862732 time: 0.0026s\n",
      "Epoch: 3000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862720 time: 0.0020s\n",
      "Epoch: 4000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862720 time: 0.0030s\n",
      "Epoch: 5000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862708 time: 0.0020s\n",
      "Epoch: 6000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862696 time: 0.0030s\n",
      "Epoch: 7000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862684 time: 0.0030s\n",
      "Epoch: 8000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862660 time: 0.0020s\n",
      "Epoch: 9000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862648 time: 0.0030s\n",
      "Epoch: 10000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862625 time: 0.0022s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 22.9561s\n",
      "Epoch: 0001 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862625 time: 0.0030s\n",
      "Epoch: 1000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862625 time: 0.0030s\n",
      "Epoch: 2000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862625 time: 0.0030s\n",
      "Epoch: 3000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862625 time: 0.0030s\n",
      "Epoch: 4000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862625 time: 0.0030s\n",
      "Epoch: 5000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862613 time: 0.0020s\n",
      "Epoch: 6000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862601 time: 0.0020s\n",
      "Epoch: 7000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862589 time: 0.0020s\n",
      "Epoch: 8000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862565 time: 0.0030s\n",
      "Epoch: 9000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862553 time: 0.0030s\n",
      "Epoch: 10000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862553 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 23.2486s\n",
      "Epoch: 0001 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862553 time: 0.0030s\n",
      "Epoch: 1000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862553 time: 0.0020s\n",
      "Epoch: 2000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862553 time: 0.0030s\n",
      "Epoch: 3000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862553 time: 0.0020s\n",
      "Epoch: 4000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862553 time: 0.0030s\n",
      "Epoch: 5000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862553 time: 0.0030s\n",
      "Epoch: 6000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862529 time: 0.0030s\n",
      "Epoch: 7000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862529 time: 0.0020s\n",
      "Epoch: 8000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862517 time: 0.0030s\n",
      "Epoch: 9000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862494 time: 0.0020s\n",
      "Epoch: 10000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862494 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 22.4779s\n",
      "Epoch: 0001 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862494 time: 0.0020s\n",
      "Epoch: 1000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862494 time: 0.0020s\n",
      "Epoch: 2000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862494 time: 0.0020s\n",
      "Epoch: 3000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862494 time: 0.0030s\n",
      "Epoch: 4000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862494 time: 0.0020s\n",
      "Epoch: 5000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862482 time: 0.0030s\n",
      "Epoch: 6000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862482 time: 0.0030s\n",
      "Epoch: 7000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862470 time: 0.0030s\n",
      "Epoch: 8000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862470 time: 0.0020s\n",
      "Epoch: 9000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862458 time: 0.0020s\n",
      "Epoch: 10000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862339 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 22.8788s\n",
      "Epoch: 0001 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862339 time: 0.0030s\n",
      "Epoch: 1000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862327 time: 0.0020s\n",
      "Epoch: 2000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862279 time: 0.0020s\n",
      "Epoch: 3000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862184 time: 0.0030s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10862005 time: 0.0020s\n",
      "Epoch: 5000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10861695 time: 0.0030s\n",
      "Epoch: 6000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10860336 time: 0.0030s\n",
      "Epoch: 7000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10856581 time: 0.0030s\n",
      "Epoch: 8000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10848308 time: 0.0030s\n",
      "Epoch: 9000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10844648 time: 0.0020s\n",
      "Epoch: 10000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10837603 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 23.0329s\n",
      "Epoch: 0001 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10837603 time: 0.0030s\n",
      "Epoch: 1000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10834897 time: 0.0020s\n",
      "Epoch: 2000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10829568 time: 0.0020s\n",
      "Epoch: 3000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10816264 time: 0.0020s\n",
      "Epoch: 4000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10780287 time: 0.0030s\n",
      "Epoch: 5000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10649562 time: 0.0020s\n",
      "Epoch: 6000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10626924 time: 0.0030s\n",
      "Epoch: 7000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10626924 time: 0.0025s\n",
      "Epoch: 8000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10626924 time: 0.0030s\n",
      "Epoch: 9000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10626924 time: 0.0030s\n",
      "Epoch: 10000 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10626924 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 23.3705s\n",
      "Epoch: 0001 Train Accuracy: 0.8072 Validation Accuracy: 0.7381 Loss: 1.10626924 time: 0.0030s\n",
      "Epoch: 1000 Train Accuracy: 0.8072 Validation Accuracy: 0.7619 Loss: 1.10561502 time: 0.0020s\n",
      "Epoch: 2000 Train Accuracy: 0.8072 Validation Accuracy: 0.7619 Loss: 1.10477042 time: 0.0030s\n",
      "Epoch: 3000 Train Accuracy: 0.8072 Validation Accuracy: 0.7619 Loss: 1.10379350 time: 0.0020s\n",
      "Epoch: 4000 Train Accuracy: 0.8072 Validation Accuracy: 0.7619 Loss: 1.10356188 time: 0.0020s\n",
      "Epoch: 5000 Train Accuracy: 0.8072 Validation Accuracy: 0.7619 Loss: 1.10356188 time: 0.0030s\n",
      "Epoch: 6000 Train Accuracy: 0.8072 Validation Accuracy: 0.7619 Loss: 1.10356188 time: 0.0030s\n",
      "Epoch: 7000 Train Accuracy: 0.8072 Validation Accuracy: 0.7619 Loss: 1.10356176 time: 0.0030s\n",
      "Epoch: 8000 Train Accuracy: 0.8072 Validation Accuracy: 0.7619 Loss: 1.10356164 time: 0.0030s\n",
      "Epoch: 9000 Train Accuracy: 0.8072 Validation Accuracy: 0.7619 Loss: 1.10356164 time: 0.0030s\n",
      "Epoch: 10000 Train Accuracy: 0.8072 Validation Accuracy: 0.7619 Loss: 1.10356164 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 22.8674s\n",
      "Epoch: 0001 Train Accuracy: 0.8072 Validation Accuracy: 0.7619 Loss: 1.10356164 time: 0.0030s\n",
      "Epoch: 1000 Train Accuracy: 0.8072 Validation Accuracy: 0.7619 Loss: 1.10356164 time: 0.0030s\n",
      "Epoch: 2000 Train Accuracy: 0.8072 Validation Accuracy: 0.7619 Loss: 1.10356164 time: 0.0020s\n",
      "Epoch: 3000 Train Accuracy: 0.8072 Validation Accuracy: 0.7619 Loss: 1.10356164 time: 0.0020s\n",
      "Epoch: 4000 Train Accuracy: 0.8072 Validation Accuracy: 0.7619 Loss: 1.10356164 time: 0.0030s\n",
      "Epoch: 5000 Train Accuracy: 0.8072 Validation Accuracy: 0.7619 Loss: 1.10356164 time: 0.0020s\n",
      "Epoch: 6000 Train Accuracy: 0.8072 Validation Accuracy: 0.7619 Loss: 1.10356164 time: 0.0020s\n",
      "Epoch: 7000 Train Accuracy: 0.8072 Validation Accuracy: 0.7619 Loss: 1.10356164 time: 0.0020s\n",
      "Epoch: 8000 Train Accuracy: 0.8072 Validation Accuracy: 0.7619 Loss: 1.10356164 time: 0.0020s\n",
      "Epoch: 9000 Train Accuracy: 0.8072 Validation Accuracy: 0.7619 Loss: 1.10356164 time: 0.0030s\n",
      "Epoch: 10000 Train Accuracy: 0.8072 Validation Accuracy: 0.7619 Loss: 1.10356164 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 23.0606s\n"
     ]
    }
   ],
   "source": [
    "# set Train %\n",
    "\n",
    "train_percentage = .8\n",
    "    \n",
    "# Train set\n",
    "number_of_rows = features[0].shape[0]\n",
    "train_indices = np.random.choice(number_of_rows, size=int(train_percentage*number_of_rows), replace=False)\n",
    "val_indices = np.setdiff1d(np.arange(adj.shape[1]),train_indices)\n",
    "\n",
    "# Start Train\n",
    "prev_loss, op = train(adj,features,labels,train_indices,val_indices,True)\n",
    "\n",
    "# Keep training recurrently until the loss stops decreasing\n",
    "loss, op = train(adj,op.cpu().detach().numpy(),labels,train_indices,val_indices)\n",
    "while loss < prev_loss :\n",
    "    prev_loss = loss\n",
    "    loss, op = train(adj,op.cpu().detach().numpy(),labels,train_indices,val_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch Basics can be found here:\n",
    "\n",
    "#### Introduction to Pytorch Tensors : https://pytorch.org/tutorials/beginner/introyt/trainingyt.html\n",
    "#### Calculating gradients using Autograd : https://pytorch.org/tutorials/beginner/introyt/autogradyt_tutorial.html\n",
    "#### Building Pytorch Models : https://pytorch.org/tutorials/beginner/introyt/modelsyt_tutorial.html\n",
    "#### Training Pytorch Models : https://pytorch.org/tutorials/beginner/introyt/trainingyt.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
