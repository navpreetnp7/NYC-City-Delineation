{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin</th>\n",
       "      <th>destination</th>\n",
       "      <th>weight</th>\n",
       "      <th>initialFeat</th>\n",
       "      <th>true_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11436</td>\n",
       "      <td>10009</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11436</td>\n",
       "      <td>10011</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11436</td>\n",
       "      <td>10013</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11436</td>\n",
       "      <td>10019</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11436</td>\n",
       "      <td>10021</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   origin  destination  weight  initialFeat  true_label\n",
       "0   11436        10009       1          4.0           4\n",
       "1   11436        10011       1          4.0           4\n",
       "2   11436        10013       1          4.0           4\n",
       "3   11436        10019       1          4.0           4\n",
       "4   11436        10021       1          4.0           4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/zips_merged.csv', delimiter=',')\n",
    "data = data.rename(columns={'total': 'weight', 'w_zip':'origin', 'h_zip':'destination'})\n",
    "data = data[data.destination.isin(data.origin.unique())]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "populationByAge = pd.read_csv('data/zicode_populationByAge.csv', delimiter=',')\n",
    "populationByAge = populationByAge.iloc[:,0:2]\n",
    "populationByAge.rename(columns={'ZIPCODE':'destination'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "housePrice = pd.read_csv('data/zipcode_housePrice.csv', delimiter=',')\n",
    "weights = [5000,12500,17500,22500,27500,32500,37500,45000,55000,65000,75000,85000\n",
    "                    ,95000,112500,137500,162500,187500,225000,275000,350000,450000,625000,875000\n",
    "                        ,1250000,1750000,2000000]\n",
    "for i in range(len(weights)):\n",
    "    housePrice.iloc[i,2:] = housePrice.iloc[i,2:]*weights[i]\n",
    "housePrice.iloc[:,1] [housePrice.iloc[:,1] == 0] = 1\n",
    "\n",
    "tmp = (housePrice.iloc[:,2:] != 0 ).sum(axis=1)\n",
    "tmp[tmp == 0] = 1\n",
    "housePrice = pd.concat([housePrice.iloc[:,0],housePrice.iloc[:,2:].sum(axis=1) / tmp ], axis = 1 )\n",
    "housePrice.rename(columns={'ZIPCODE':'destination'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = pd.read_csv('data/zips_area.csv', delimiter=',')\n",
    "area = area.iloc[:,:2]\n",
    "area.rename(columns={'ZIPCODE':'destination'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "income = pd.read_csv('data/zipcode_income.csv', delimiter=',')\n",
    "income = income.iloc[:,:2]\n",
    "income[income.isna()] = 0\n",
    "income.rename(columns={'ZIPCODE':'destination'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "populationJobs = pd.read_csv('data/zipcode_population_Jobs.csv', delimiter=',')\n",
    "populationJobs = populationJobs.iloc[:,:2]\n",
    "populationJobs.rename(columns={'ZIPCODE':'destination'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(populationByAge)\n",
    "data = data.merge(housePrice)\n",
    "data = data.merge(area)\n",
    "data = data.merge(income)\n",
    "data = data.merge(populationJobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[:,5:]=(data.iloc[:,5:]-data.iloc[:,5:].min())/(data.iloc[:,5:].max()-data.iloc[:,5:].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin</th>\n",
       "      <th>destination</th>\n",
       "      <th>weight</th>\n",
       "      <th>initialFeat</th>\n",
       "      <th>true_label</th>\n",
       "      <th>Estimate!!Total!!Total population</th>\n",
       "      <th>0</th>\n",
       "      <th>AREA</th>\n",
       "      <th>median_familyIncome(USD)</th>\n",
       "      <th>totalJobs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11436</td>\n",
       "      <td>10009</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.300165</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.032183</td>\n",
       "      <td>0.243977</td>\n",
       "      <td>0.042630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11213</td>\n",
       "      <td>10009</td>\n",
       "      <td>14</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.300165</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.032183</td>\n",
       "      <td>0.243977</td>\n",
       "      <td>0.042630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11212</td>\n",
       "      <td>10009</td>\n",
       "      <td>27</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.300165</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.032183</td>\n",
       "      <td>0.243977</td>\n",
       "      <td>0.042630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11225</td>\n",
       "      <td>10009</td>\n",
       "      <td>26</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.300165</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.032183</td>\n",
       "      <td>0.243977</td>\n",
       "      <td>0.042630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11218</td>\n",
       "      <td>10009</td>\n",
       "      <td>60</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.300165</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.032183</td>\n",
       "      <td>0.243977</td>\n",
       "      <td>0.042630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36407</th>\n",
       "      <td>11211</td>\n",
       "      <td>11371</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36408</th>\n",
       "      <td>11373</td>\n",
       "      <td>11371</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36409</th>\n",
       "      <td>10168</td>\n",
       "      <td>11371</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36410</th>\n",
       "      <td>10278</td>\n",
       "      <td>11371</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36411</th>\n",
       "      <td>10036</td>\n",
       "      <td>11371</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36412 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       origin  destination  weight  initialFeat  true_label  \\\n",
       "0       11436        10009       1          4.0           4   \n",
       "1       11213        10009      14          3.0           3   \n",
       "2       11212        10009      27          3.0           3   \n",
       "3       11225        10009      26          3.0           3   \n",
       "4       11218        10009      60          3.0           3   \n",
       "...       ...          ...     ...          ...         ...   \n",
       "36407   11211        11371       7          1.0           3   \n",
       "36408   11373        11371       3          4.0           4   \n",
       "36409   10168        11371       1          1.0           1   \n",
       "36410   10278        11371       1          1.0           1   \n",
       "36411   10036        11371       5          1.0           1   \n",
       "\n",
       "       Estimate!!Total!!Total population         0      AREA  \\\n",
       "0                               0.300165  0.005332  0.032183   \n",
       "1                               0.300165  0.005332  0.032183   \n",
       "2                               0.300165  0.005332  0.032183   \n",
       "3                               0.300165  0.005332  0.032183   \n",
       "4                               0.300165  0.005332  0.032183   \n",
       "...                                  ...       ...       ...   \n",
       "36407                           0.000000  0.000000  0.063146   \n",
       "36408                           0.000000  0.000000  0.063146   \n",
       "36409                           0.000000  0.000000  0.063146   \n",
       "36410                           0.000000  0.000000  0.063146   \n",
       "36411                           0.000000  0.000000  0.063146   \n",
       "\n",
       "       median_familyIncome(USD)  totalJobs  \n",
       "0                      0.243977   0.042630  \n",
       "1                      0.243977   0.042630  \n",
       "2                      0.243977   0.042630  \n",
       "3                      0.243977   0.042630  \n",
       "4                      0.243977   0.042630  \n",
       "...                         ...        ...  \n",
       "36407                  0.000000   0.050874  \n",
       "36408                  0.000000   0.050874  \n",
       "36409                  0.000000   0.050874  \n",
       "36410                  0.000000   0.050874  \n",
       "36411                  0.000000   0.050874  \n",
       "\n",
       "[36412 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "weight_decay = 10e-4\n",
    "epochs = 10001\n",
    "seed = 165\n",
    "hidden = 10\n",
    "lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(adj):\n",
    "\n",
    "    adj = torch.FloatTensor(adj)\n",
    "    adj_id = torch.FloatTensor(torch.eye(adj.shape[1]))\n",
    "    adj_id = adj_id.reshape((1, adj.shape[1], adj.shape[1]))\n",
    "    adj_id = adj_id.repeat(adj.shape[0], 1, 1)\n",
    "    adj = adj + adj_id\n",
    "    rowsum = torch.FloatTensor(adj.sum(2))\n",
    "    degree_mat_inv_sqrt = torch.diag_embed(torch.float_power(rowsum,-0.5), dim1=-2, dim2=-1).float()\n",
    "    adj_norm = torch.bmm(torch.transpose(torch.bmm(adj,degree_mat_inv_sqrt),1,2),degree_mat_inv_sqrt)\n",
    "\n",
    "    return adj_norm\n",
    "\n",
    "\n",
    "def doublerelu(x):\n",
    "    return torch.clamp(x, 0, 1)\n",
    "\n",
    "class GNN1Layer(Module):\n",
    "\n",
    "    def __init__(self, batch_size, in_features, out_features, first):\n",
    "        super(GNN1Layer, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        weight1_eye = torch.FloatTensor(torch.eye(in_features, out_features))\n",
    "        weight1_eye = weight1_eye.reshape((1, in_features, out_features))\n",
    "        weight1_eye = weight1_eye.repeat(batch_size, 1, 1)\n",
    "        self.weight1 = Parameter(weight1_eye)\n",
    "        if not first:\n",
    "            self.weight2 = Parameter(torch.zeros(batch_size, in_features, out_features))\n",
    "        else:\n",
    "            self.weight2 = Parameter(torch.empty(batch_size, in_features, out_features))\n",
    "            nn.init.kaiming_normal_(self.weight2, mode='fan_out')\n",
    "\n",
    "    def forward(self, input, adj):\n",
    "        v1 = torch.bmm(input, self.weight1)\n",
    "        v2 = torch.bmm(torch.bmm(adj, input), self.weight2)\n",
    "        output = v1 + v2\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN1(nn.Module):\n",
    "\n",
    "    def __init__(self, batch_size, nfeat, ndim, hidden, first):\n",
    "        super(GNN1, self).__init__()\n",
    "\n",
    "        self.gc1 = GNN1Layer(batch_size, nfeat, ndim, first)\n",
    "\n",
    "    def forward(self, x, adj, random_indices):\n",
    "        f = torch.clone(x)\n",
    "        x = doublerelu(self.gc1(x, adj))\n",
    "        x = x/x.sum(axis=2).unsqueeze(2) #normalize st sum = 1\n",
    "\n",
    "        f[0][random_indices, :x.shape[2]] = x[0][random_indices, :]\n",
    "        \n",
    "        return f[:,:,:x.shape[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(adj,features,labels,random_indices,first=False):\n",
    "    \n",
    "    adj_norm = normalize(adj)\n",
    "    \n",
    "    labels = labels - 1\n",
    "    \n",
    "    adj = torch.FloatTensor(adj)\n",
    "    adj_norm = torch.FloatTensor(adj_norm)\n",
    "    features = torch.FloatTensor(features)\n",
    "    labels = torch.FloatTensor(labels)\n",
    "    \n",
    "    model = GNN1(batch_size=adj.shape[0],\n",
    "                nfeat=features.shape[-1],\n",
    "                ndim=nb_label,\n",
    "                hidden=hidden,\n",
    "                first=first)\n",
    "    if cuda:\n",
    "        model.cuda()\n",
    "        features = features.cuda()\n",
    "        adj = adj.cuda()\n",
    "        adj_norm = adj_norm.cuda()\n",
    "        labels = labels.cuda()\n",
    "    \n",
    "    # Train model\n",
    "    t_total = time.time()\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(),\n",
    "                           lr=lr, weight_decay=weight_decay)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        t = time.time()\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(features, adj_norm, random_indices)\n",
    "            \n",
    "        accuracy = torch.sum(torch.argmax(output,axis=2)==labels.reshape(1,-1))/labels.shape[0]\n",
    "        \n",
    "        loss = criterion(output[0],labels.reshape(-1).long())\n",
    "\n",
    "        loss.backward(retain_graph=True)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch == 0:\n",
    "            best_loss = loss\n",
    "            best_output = output\n",
    "            best_acc = accuracy\n",
    "        else:\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "                best_output = output\n",
    "                best_acc = accuracy\n",
    "\n",
    "        if epoch % 1000 == 0:\n",
    "            print('Epoch: {:04d}'.format(epoch + 1),\n",
    "                  'Accuracy: {:.4f}'.format(best_acc.item()),\n",
    "                  'Loss: {:.8f}'.format(best_loss.item()),\n",
    "                  'time: {:.4f}s'.format(time.time() - t))\n",
    "            \n",
    "    print(\"Optimization Finished!\")\n",
    "    print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
    "    \n",
    "    return best_loss,best_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svdApprox(adj, dim, relu=False):\n",
    "    adj = torch.FloatTensor(adj[0])\n",
    "    U, S, Vh = torch.linalg.svd(adj)\n",
    "    mu = torch.matmul(torch.matmul(U[:, :dim], torch.diag(S[:dim])), Vh[:dim, :])\n",
    "\n",
    "    embedx = torch.matmul(U[:, :dim], torch.diag(torch.pow(S[:dim], 0.5)))\n",
    "    embedy = torch.transpose(torch.matmul(torch.diag(torch.pow(S[:dim], 0.5)), Vh[:dim, :]), 0, 1)\n",
    "\n",
    "    return embedx, embedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "\n",
    "    G = nx.from_pandas_edgelist(data, 'origin', 'destination', 'weight',create_using=nx.DiGraph())\n",
    "    adj_list = np.array([nx.adjacency_matrix(G).todense()], dtype=float)\n",
    "    #init_feat = np.array(data.groupby('origin')['initialFeat'].agg(['unique']))\n",
    "    \n",
    "    init_feat1 = np.array(data.groupby('origin')['Estimate!!Total!!Total population'].agg(['unique']))\n",
    "    init_feat1 = np.array(list(map(lambda x: x[0][0], init_feat1))).reshape(-1, 1)\n",
    "    init_feat2 = np.array(data.groupby('origin')[0].agg(['unique']))\n",
    "    init_feat2 = np.array(list(map(lambda x: x[0][0], init_feat2))).reshape(-1, 1)\n",
    "    init_feat3 = np.array(data.groupby('origin')['AREA'].agg(['unique']))\n",
    "    init_feat3 = np.array(list(map(lambda x: x[0][0], init_feat3))).reshape(-1, 1)\n",
    "    init_feat4 = np.array(data.groupby('origin')['median_familyIncome(USD)'].agg(['unique']))\n",
    "    init_feat4 = np.array(list(map(lambda x: x[0][0], init_feat4))).reshape(-1, 1)\n",
    "    init_feat5 = np.array(data.groupby('origin')['totalJobs'].agg(['unique']))\n",
    "    init_feat5 = np.array(list(map(lambda x: x[0][0], init_feat5))).reshape(-1, 1)\n",
    "    \n",
    "    init_feat = np.concatenate([init_feat1,init_feat2,init_feat3,init_feat4,init_feat5],axis=1)\n",
    "    \n",
    "    true_label = np.array(data.groupby('origin')['true_label'].agg(['unique']))\n",
    "    \n",
    "    true_label = np.array(list(map(lambda x: x[0][0], true_label))).reshape(-1, 1)\n",
    "    return adj_list,init_feat,true_label\n",
    "\n",
    "adj,feature,labels = load_data()\n",
    "\n",
    "features = np.expand_dims(feature, axis=0)\n",
    "\n",
    "#feature = feature - 1\n",
    "#nb_label = int(max(feature)) + 1\n",
    "#featuress = np.eye(nb_label)[np.array(feature,dtype=int).reshape(1,-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_feat = np.array(data.groupby('origin')['initialFeat'].agg(['unique']))\n",
    "init_feat = np.array(list(map(lambda x: x[0][0], init_feat))).reshape(-1, 1)\n",
    "init_feat = init_feat - 1\n",
    "nb_label = int(max(init_feat)) + 1\n",
    "\n",
    "init_feat = np.eye(nb_label)[np.array(init_feat,dtype=int).reshape(1,-1)]\n",
    "\n",
    "embedx, embedy = svdApprox(adj,dim=3)\n",
    "embedx = np.array(embedx.unsqueeze(0))\n",
    "embedy = np.array(embedy.unsqueeze(0))\n",
    "features = np.concatenate([init_feat,embedx,embedy],axis=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Masked 100% of nodes\n",
      "\n",
      "Epoch: 0001 Accuracy: 0.3750 Loss: 1.53493810 time: 0.0020s\n",
      "Epoch: 1001 Accuracy: 0.4279 Loss: 1.48245108 time: 0.0020s\n",
      "Epoch: 2001 Accuracy: 0.4471 Loss: 1.45914567 time: 0.0020s\n",
      "Epoch: 3001 Accuracy: 0.5240 Loss: 1.42639744 time: 0.0030s\n",
      "Epoch: 4001 Accuracy: 0.5288 Loss: 1.38942194 time: 0.0030s\n",
      "Epoch: 5001 Accuracy: 0.5288 Loss: 1.38942194 time: 0.0020s\n",
      "Epoch: 6001 Accuracy: 0.5288 Loss: 1.38942194 time: 0.0020s\n",
      "Epoch: 7001 Accuracy: 0.5288 Loss: 1.38942194 time: 0.0010s\n",
      "Epoch: 8001 Accuracy: 0.5288 Loss: 1.38942194 time: 0.0020s\n",
      "Epoch: 9001 Accuracy: 0.5288 Loss: 1.38942194 time: 0.0020s\n",
      "Epoch: 10001 Accuracy: 0.5288 Loss: 1.38942194 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 19.6913s\n",
      "Epoch: 0001 Accuracy: 0.5288 Loss: 1.38942194 time: 0.0030s\n",
      "Epoch: 1001 Accuracy: 0.5337 Loss: 1.35994554 time: 0.0020s\n",
      "Epoch: 2001 Accuracy: 0.5288 Loss: 1.34822702 time: 0.0020s\n",
      "Epoch: 3001 Accuracy: 0.5288 Loss: 1.33670127 time: 0.0020s\n",
      "Epoch: 4001 Accuracy: 0.5385 Loss: 1.33387387 time: 0.0020s\n",
      "Epoch: 5001 Accuracy: 0.5385 Loss: 1.33387387 time: 0.0030s\n",
      "Epoch: 6001 Accuracy: 0.5385 Loss: 1.33387387 time: 0.0030s\n",
      "Epoch: 7001 Accuracy: 0.5385 Loss: 1.33387387 time: 0.0020s\n",
      "Epoch: 8001 Accuracy: 0.5385 Loss: 1.33387387 time: 0.0020s\n",
      "Epoch: 9001 Accuracy: 0.5385 Loss: 1.33387387 time: 0.0020s\n",
      "Epoch: 10001 Accuracy: 0.5385 Loss: 1.33387387 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 20.2809s\n",
      "Epoch: 0001 Accuracy: 0.5385 Loss: 1.33387387 time: 0.0020s\n",
      "Epoch: 1001 Accuracy: 0.5481 Loss: 1.32415521 time: 0.0021s\n",
      "Epoch: 2001 Accuracy: 0.5673 Loss: 1.31324756 time: 0.0020s\n",
      "Epoch: 3001 Accuracy: 0.5769 Loss: 1.30359888 time: 0.0020s\n",
      "Epoch: 4001 Accuracy: 0.6058 Loss: 1.29467142 time: 0.0020s\n",
      "Epoch: 5001 Accuracy: 0.6058 Loss: 1.29467142 time: 0.0020s\n",
      "Epoch: 6001 Accuracy: 0.6010 Loss: 1.29204190 time: 0.0030s\n",
      "Epoch: 7001 Accuracy: 0.6010 Loss: 1.29204190 time: 0.0020s\n",
      "Epoch: 8001 Accuracy: 0.6010 Loss: 1.29204190 time: 0.0020s\n",
      "Epoch: 9001 Accuracy: 0.6010 Loss: 1.29204190 time: 0.0020s\n",
      "Epoch: 10001 Accuracy: 0.6010 Loss: 1.29204190 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 20.8810s\n",
      "Epoch: 0001 Accuracy: 0.6010 Loss: 1.29204190 time: 0.0030s\n",
      "Epoch: 1001 Accuracy: 0.5962 Loss: 1.27931798 time: 0.0020s\n",
      "Epoch: 2001 Accuracy: 0.5962 Loss: 1.27042902 time: 0.0020s\n",
      "Epoch: 3001 Accuracy: 0.6202 Loss: 1.25289035 time: 0.0020s\n",
      "Epoch: 4001 Accuracy: 0.6394 Loss: 1.23954797 time: 0.0020s\n",
      "Epoch: 5001 Accuracy: 0.6394 Loss: 1.23954797 time: 0.0030s\n",
      "Epoch: 6001 Accuracy: 0.6394 Loss: 1.23954797 time: 0.0020s\n",
      "Epoch: 7001 Accuracy: 0.6394 Loss: 1.23954797 time: 0.0020s\n",
      "Epoch: 8001 Accuracy: 0.6394 Loss: 1.23954797 time: 0.0020s\n",
      "Epoch: 9001 Accuracy: 0.6394 Loss: 1.23954797 time: 0.0020s\n",
      "Epoch: 10001 Accuracy: 0.6394 Loss: 1.23954797 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 21.3589s\n",
      "Epoch: 0001 Accuracy: 0.6394 Loss: 1.23954785 time: 0.0030s\n",
      "Epoch: 1001 Accuracy: 0.6394 Loss: 1.23700392 time: 0.0020s\n",
      "Epoch: 2001 Accuracy: 0.6442 Loss: 1.23388779 time: 0.0030s\n",
      "Epoch: 3001 Accuracy: 0.6394 Loss: 1.23021042 time: 0.0030s\n",
      "Epoch: 4001 Accuracy: 0.6635 Loss: 1.22135746 time: 0.0020s\n",
      "Epoch: 5001 Accuracy: 0.6635 Loss: 1.22091663 time: 0.0030s\n",
      "Epoch: 6001 Accuracy: 0.6635 Loss: 1.22091663 time: 0.0030s\n",
      "Epoch: 7001 Accuracy: 0.6635 Loss: 1.22091663 time: 0.0030s\n",
      "Epoch: 8001 Accuracy: 0.6635 Loss: 1.22091663 time: 0.0020s\n",
      "Epoch: 9001 Accuracy: 0.6635 Loss: 1.21103501 time: 0.0030s\n",
      "Epoch: 10001 Accuracy: 0.6490 Loss: 1.20759594 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 22.2834s\n",
      "Epoch: 0001 Accuracy: 0.6490 Loss: 1.20759594 time: 0.0030s\n",
      "Epoch: 1001 Accuracy: 0.6635 Loss: 1.20320666 time: 0.0030s\n",
      "Epoch: 2001 Accuracy: 0.7115 Loss: 1.19225359 time: 0.0020s\n",
      "Epoch: 3001 Accuracy: 0.7212 Loss: 1.18762720 time: 0.0030s\n",
      "Epoch: 4001 Accuracy: 0.7212 Loss: 1.18762720 time: 0.0030s\n",
      "Epoch: 5001 Accuracy: 0.7212 Loss: 1.18762720 time: 0.0020s\n",
      "Epoch: 6001 Accuracy: 0.7212 Loss: 1.18762720 time: 0.0030s\n",
      "Epoch: 7001 Accuracy: 0.7212 Loss: 1.18762720 time: 0.0020s\n",
      "Epoch: 8001 Accuracy: 0.7212 Loss: 1.18762720 time: 0.0020s\n",
      "Epoch: 9001 Accuracy: 0.7212 Loss: 1.18762720 time: 0.0030s\n",
      "Epoch: 10001 Accuracy: 0.7212 Loss: 1.18762720 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 24.8284s\n",
      "Epoch: 0001 Accuracy: 0.7212 Loss: 1.18762720 time: 0.0030s\n",
      "Epoch: 1001 Accuracy: 0.7163 Loss: 1.18335664 time: 0.0020s\n",
      "Epoch: 2001 Accuracy: 0.7115 Loss: 1.18005121 time: 0.0020s\n",
      "Epoch: 3001 Accuracy: 0.7212 Loss: 1.17562556 time: 0.0020s\n",
      "Epoch: 4001 Accuracy: 0.7163 Loss: 1.17230892 time: 0.0030s\n",
      "Epoch: 5001 Accuracy: 0.7163 Loss: 1.17091787 time: 0.0020s\n",
      "Epoch: 6001 Accuracy: 0.7163 Loss: 1.17045236 time: 0.0030s\n",
      "Epoch: 7001 Accuracy: 0.7163 Loss: 1.17045236 time: 0.0020s\n",
      "Epoch: 8001 Accuracy: 0.7163 Loss: 1.17045236 time: 0.0030s\n",
      "Epoch: 9001 Accuracy: 0.7163 Loss: 1.17045236 time: 0.0030s\n",
      "Epoch: 10001 Accuracy: 0.7163 Loss: 1.17045236 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 24.0963s\n",
      "Epoch: 0001 Accuracy: 0.7163 Loss: 1.17045236 time: 0.0030s\n",
      "Epoch: 1001 Accuracy: 0.7163 Loss: 1.17025423 time: 0.0020s\n",
      "Epoch: 2001 Accuracy: 0.7163 Loss: 1.16982555 time: 0.0020s\n",
      "Epoch: 3001 Accuracy: 0.7163 Loss: 1.16903234 time: 0.0020s\n",
      "Epoch: 4001 Accuracy: 0.7260 Loss: 1.16681385 time: 0.0030s\n",
      "Epoch: 5001 Accuracy: 0.7308 Loss: 1.15828776 time: 0.0030s\n",
      "Epoch: 6001 Accuracy: 0.7308 Loss: 1.15652406 time: 0.0020s\n",
      "Epoch: 7001 Accuracy: 0.7452 Loss: 1.15499294 time: 0.0030s\n",
      "Epoch: 8001 Accuracy: 0.7452 Loss: 1.15411103 time: 0.0030s\n",
      "Epoch: 9001 Accuracy: 0.7452 Loss: 1.15411103 time: 0.0030s\n",
      "Epoch: 10001 Accuracy: 0.7452 Loss: 1.15411103 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 23.7983s\n",
      "Epoch: 0001 Accuracy: 0.7452 Loss: 1.15411103 time: 0.0030s\n",
      "Epoch: 1001 Accuracy: 0.7404 Loss: 1.15401196 time: 0.0030s\n",
      "Epoch: 2001 Accuracy: 0.7404 Loss: 1.15380991 time: 0.0030s\n",
      "Epoch: 3001 Accuracy: 0.7404 Loss: 1.15326774 time: 0.0020s\n",
      "Epoch: 4001 Accuracy: 0.7500 Loss: 1.15159678 time: 0.0030s\n",
      "Epoch: 5001 Accuracy: 0.7500 Loss: 1.15103519 time: 0.0020s\n",
      "Epoch: 6001 Accuracy: 0.7452 Loss: 1.14954710 time: 0.0020s\n",
      "Epoch: 7001 Accuracy: 0.7500 Loss: 1.14674592 time: 0.0030s\n",
      "Epoch: 8001 Accuracy: 0.7500 Loss: 1.14674592 time: 0.0020s\n",
      "Epoch: 9001 Accuracy: 0.7500 Loss: 1.14674592 time: 0.0020s\n",
      "Epoch: 10001 Accuracy: 0.7500 Loss: 1.14674592 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 23.9121s\n",
      "Epoch: 0001 Accuracy: 0.7500 Loss: 1.14674592 time: 0.0020s\n",
      "Epoch: 1001 Accuracy: 0.7500 Loss: 1.14620423 time: 0.0020s\n",
      "Epoch: 2001 Accuracy: 0.7500 Loss: 1.14569080 time: 0.0020s\n",
      "Epoch: 3001 Accuracy: 0.7500 Loss: 1.14507842 time: 0.0030s\n",
      "Epoch: 4001 Accuracy: 0.7500 Loss: 1.14420438 time: 0.0030s\n",
      "Epoch: 5001 Accuracy: 0.7548 Loss: 1.14263105 time: 0.0030s\n",
      "Epoch: 6001 Accuracy: 0.7596 Loss: 1.14084291 time: 0.0030s\n",
      "Epoch: 7001 Accuracy: 0.7548 Loss: 1.14068031 time: 0.0030s\n",
      "Epoch: 8001 Accuracy: 0.7548 Loss: 1.14037836 time: 0.0020s\n",
      "Epoch: 9001 Accuracy: 0.7596 Loss: 1.13585544 time: 0.0030s\n",
      "Epoch: 10001 Accuracy: 0.7596 Loss: 1.13560975 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 22.8439s\n",
      "Epoch: 0001 Accuracy: 0.7596 Loss: 1.13560975 time: 0.0020s\n",
      "Epoch: 1001 Accuracy: 0.7596 Loss: 1.13559103 time: 0.0020s\n",
      "Epoch: 2001 Accuracy: 0.7596 Loss: 1.13555169 time: 0.0030s\n",
      "Epoch: 3001 Accuracy: 0.7596 Loss: 1.13550591 time: 0.0020s\n",
      "Epoch: 4001 Accuracy: 0.7596 Loss: 1.13546634 time: 0.0020s\n",
      "Epoch: 5001 Accuracy: 0.7596 Loss: 1.13541365 time: 0.0030s\n",
      "Epoch: 6001 Accuracy: 0.7644 Loss: 1.13533926 time: 0.0020s\n",
      "Epoch: 7001 Accuracy: 0.7644 Loss: 1.13521016 time: 0.0030s\n",
      "Epoch: 8001 Accuracy: 0.7644 Loss: 1.13489830 time: 0.0020s\n",
      "Epoch: 9001 Accuracy: 0.7644 Loss: 1.13340592 time: 0.0020s\n",
      "Epoch: 10001 Accuracy: 0.7644 Loss: 1.13340592 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 22.1837s\n",
      "Epoch: 0001 Accuracy: 0.7644 Loss: 1.13340592 time: 0.0030s\n",
      "Epoch: 1001 Accuracy: 0.7692 Loss: 1.13321829 time: 0.0020s\n",
      "Epoch: 2001 Accuracy: 0.7692 Loss: 1.13313222 time: 0.0020s\n",
      "Epoch: 3001 Accuracy: 0.7740 Loss: 1.13304520 time: 0.0020s\n",
      "Epoch: 4001 Accuracy: 0.7740 Loss: 1.13294840 time: 0.0020s\n",
      "Epoch: 5001 Accuracy: 0.7740 Loss: 1.13283682 time: 0.0020s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6001 Accuracy: 0.7740 Loss: 1.13269830 time: 0.0030s\n",
      "Epoch: 7001 Accuracy: 0.7740 Loss: 1.13249767 time: 0.0030s\n",
      "Epoch: 8001 Accuracy: 0.7740 Loss: 1.13198626 time: 0.0020s\n",
      "Epoch: 9001 Accuracy: 0.7692 Loss: 1.12637949 time: 0.0030s\n",
      "Epoch: 10001 Accuracy: 0.7692 Loss: 1.12637949 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 21.9742s\n",
      "Epoch: 0001 Accuracy: 0.7692 Loss: 1.12637949 time: 0.0030s\n",
      "Epoch: 1001 Accuracy: 0.7692 Loss: 1.12628126 time: 0.0020s\n",
      "Epoch: 2001 Accuracy: 0.7740 Loss: 1.12609851 time: 0.0020s\n",
      "Epoch: 3001 Accuracy: 0.7692 Loss: 1.12594247 time: 0.0020s\n",
      "Epoch: 4001 Accuracy: 0.7692 Loss: 1.12576962 time: 0.0020s\n",
      "Epoch: 5001 Accuracy: 0.7788 Loss: 1.12559521 time: 0.0020s\n",
      "Epoch: 6001 Accuracy: 0.7788 Loss: 1.12540269 time: 0.0020s\n",
      "Epoch: 7001 Accuracy: 0.7788 Loss: 1.12518275 time: 0.0020s\n",
      "Epoch: 8001 Accuracy: 0.7788 Loss: 1.12491333 time: 0.0030s\n",
      "Epoch: 9001 Accuracy: 0.7788 Loss: 1.12430274 time: 0.0020s\n",
      "Epoch: 10001 Accuracy: 0.7788 Loss: 1.12352586 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 21.6746s\n",
      "Epoch: 0001 Accuracy: 0.7788 Loss: 1.12352586 time: 0.0030s\n",
      "Epoch: 1001 Accuracy: 0.7788 Loss: 1.12351251 time: 0.0030s\n",
      "Epoch: 2001 Accuracy: 0.7788 Loss: 1.12348545 time: 0.0030s\n",
      "Epoch: 3001 Accuracy: 0.7788 Loss: 1.12344933 time: 0.0030s\n",
      "Epoch: 4001 Accuracy: 0.7788 Loss: 1.12340033 time: 0.0020s\n",
      "Epoch: 5001 Accuracy: 0.7788 Loss: 1.12333310 time: 0.0020s\n",
      "Epoch: 6001 Accuracy: 0.7788 Loss: 1.12320781 time: 0.0030s\n",
      "Epoch: 7001 Accuracy: 0.7788 Loss: 1.12282622 time: 0.0020s\n",
      "Epoch: 8001 Accuracy: 0.7788 Loss: 1.12282622 time: 0.0020s\n",
      "Epoch: 9001 Accuracy: 0.7788 Loss: 1.12282622 time: 0.0020s\n",
      "Epoch: 10001 Accuracy: 0.7788 Loss: 1.12282622 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 21.8396s\n",
      "Epoch: 0001 Accuracy: 0.7788 Loss: 1.12282622 time: 0.0030s\n",
      "Epoch: 1001 Accuracy: 0.7788 Loss: 1.12280107 time: 0.0020s\n",
      "Epoch: 2001 Accuracy: 0.7788 Loss: 1.12273741 time: 0.0020s\n",
      "Epoch: 3001 Accuracy: 0.7788 Loss: 1.12259817 time: 0.0020s\n",
      "Epoch: 4001 Accuracy: 0.7837 Loss: 1.11979508 time: 0.0030s\n",
      "Epoch: 5001 Accuracy: 0.7837 Loss: 1.11979508 time: 0.0030s\n",
      "Epoch: 6001 Accuracy: 0.7837 Loss: 1.11979508 time: 0.0020s\n",
      "Epoch: 7001 Accuracy: 0.7837 Loss: 1.11979508 time: 0.0030s\n",
      "Epoch: 8001 Accuracy: 0.7837 Loss: 1.11979508 time: 0.0030s\n",
      "Epoch: 9001 Accuracy: 0.7837 Loss: 1.11979508 time: 0.0020s\n",
      "Epoch: 10001 Accuracy: 0.7837 Loss: 1.11979508 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 21.9463s\n",
      "Epoch: 0001 Accuracy: 0.7837 Loss: 1.11979508 time: 0.0020s\n",
      "Epoch: 1001 Accuracy: 0.7837 Loss: 1.11938584 time: 0.0020s\n",
      "Epoch: 2001 Accuracy: 0.7837 Loss: 1.11910975 time: 0.0020s\n",
      "Epoch: 3001 Accuracy: 0.7837 Loss: 1.11892283 time: 0.0020s\n",
      "Epoch: 4001 Accuracy: 0.7837 Loss: 1.11887050 time: 0.0020s\n",
      "Epoch: 5001 Accuracy: 0.7837 Loss: 1.11882341 time: 0.0020s\n",
      "Epoch: 6001 Accuracy: 0.7837 Loss: 1.11876690 time: 0.0020s\n",
      "Epoch: 7001 Accuracy: 0.7837 Loss: 1.11863732 time: 0.0020s\n",
      "Epoch: 8001 Accuracy: 0.7837 Loss: 1.11854625 time: 0.0030s\n",
      "Epoch: 9001 Accuracy: 0.7837 Loss: 1.11854625 time: 0.0020s\n",
      "Epoch: 10001 Accuracy: 0.7837 Loss: 1.11854625 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 21.8295s\n",
      "Epoch: 0001 Accuracy: 0.7837 Loss: 1.11854625 time: 0.0020s\n",
      "Epoch: 1001 Accuracy: 0.7837 Loss: 1.11853695 time: 0.0020s\n",
      "Epoch: 2001 Accuracy: 0.7837 Loss: 1.11852086 time: 0.0030s\n",
      "Epoch: 3001 Accuracy: 0.7837 Loss: 1.11849046 time: 0.0030s\n",
      "Epoch: 4001 Accuracy: 0.7837 Loss: 1.11843038 time: 0.0030s\n",
      "Epoch: 5001 Accuracy: 0.7837 Loss: 1.11829042 time: 0.0020s\n",
      "Epoch: 6001 Accuracy: 0.7837 Loss: 1.11782944 time: 0.0020s\n",
      "Epoch: 7001 Accuracy: 0.7837 Loss: 1.11782944 time: 0.0020s\n",
      "Epoch: 8001 Accuracy: 0.7837 Loss: 1.11782944 time: 0.0020s\n",
      "Epoch: 9001 Accuracy: 0.7837 Loss: 1.11782944 time: 0.0020s\n",
      "Epoch: 10001 Accuracy: 0.7837 Loss: 1.11782944 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 21.9732s\n",
      "Epoch: 0001 Accuracy: 0.7837 Loss: 1.11782944 time: 0.0030s\n",
      "Epoch: 1001 Accuracy: 0.7837 Loss: 1.11780345 time: 0.0020s\n",
      "Epoch: 2001 Accuracy: 0.7837 Loss: 1.11771393 time: 0.0020s\n",
      "Epoch: 3001 Accuracy: 0.7837 Loss: 1.11749661 time: 0.0020s\n",
      "Epoch: 4001 Accuracy: 0.7837 Loss: 1.11700320 time: 0.0020s\n",
      "Epoch: 5001 Accuracy: 0.7837 Loss: 1.11603582 time: 0.0030s\n",
      "Epoch: 6001 Accuracy: 0.7837 Loss: 1.11603582 time: 0.0030s\n",
      "Epoch: 7001 Accuracy: 0.7837 Loss: 1.11603582 time: 0.0030s\n",
      "Epoch: 8001 Accuracy: 0.7837 Loss: 1.11603582 time: 0.0020s\n",
      "Epoch: 9001 Accuracy: 0.7837 Loss: 1.11603582 time: 0.0020s\n",
      "Epoch: 10001 Accuracy: 0.7837 Loss: 1.11603582 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 22.3837s\n",
      "Epoch: 0001 Accuracy: 0.7837 Loss: 1.11603582 time: 0.0030s\n",
      "Epoch: 1001 Accuracy: 0.7837 Loss: 1.11569118 time: 0.0020s\n",
      "Epoch: 2001 Accuracy: 0.7837 Loss: 1.11517012 time: 0.0030s\n",
      "Epoch: 3001 Accuracy: 0.7885 Loss: 1.11431658 time: 0.0030s\n",
      "Epoch: 4001 Accuracy: 0.7885 Loss: 1.11256003 time: 0.0020s\n",
      "Epoch: 5001 Accuracy: 0.7885 Loss: 1.11256003 time: 0.0020s\n",
      "Epoch: 6001 Accuracy: 0.7885 Loss: 1.11256003 time: 0.0020s\n",
      "Epoch: 7001 Accuracy: 0.7885 Loss: 1.11256003 time: 0.0020s\n",
      "Epoch: 8001 Accuracy: 0.7885 Loss: 1.11256003 time: 0.0020s\n",
      "Epoch: 9001 Accuracy: 0.7885 Loss: 1.11256003 time: 0.0020s\n",
      "Epoch: 10001 Accuracy: 0.7885 Loss: 1.11256003 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 23.4034s\n",
      "Epoch: 0001 Accuracy: 0.7885 Loss: 1.11256003 time: 0.0020s\n",
      "Epoch: 1001 Accuracy: 0.7885 Loss: 1.11171043 time: 0.0030s\n",
      "Epoch: 2001 Accuracy: 0.7933 Loss: 1.11075449 time: 0.0020s\n",
      "Epoch: 3001 Accuracy: 0.7933 Loss: 1.10976493 time: 0.0020s\n",
      "Epoch: 4001 Accuracy: 0.7933 Loss: 1.10917497 time: 0.0020s\n",
      "Epoch: 5001 Accuracy: 0.7981 Loss: 1.10857499 time: 0.0020s\n",
      "Epoch: 6001 Accuracy: 0.7981 Loss: 1.10857499 time: 0.0020s\n",
      "Epoch: 7001 Accuracy: 0.7981 Loss: 1.10857499 time: 0.0030s\n",
      "Epoch: 8001 Accuracy: 0.7981 Loss: 1.10857499 time: 0.0020s\n",
      "Epoch: 9001 Accuracy: 0.7981 Loss: 1.10857499 time: 0.0020s\n",
      "Epoch: 10001 Accuracy: 0.7981 Loss: 1.10857499 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 21.8043s\n",
      "Epoch: 0001 Accuracy: 0.7981 Loss: 1.10857499 time: 0.0020s\n",
      "Epoch: 1001 Accuracy: 0.7933 Loss: 1.10813951 time: 0.0020s\n",
      "Epoch: 2001 Accuracy: 0.7933 Loss: 1.10696435 time: 0.0020s\n",
      "Epoch: 3001 Accuracy: 0.7933 Loss: 1.10539329 time: 0.0020s\n",
      "Epoch: 4001 Accuracy: 0.7981 Loss: 1.10522127 time: 0.0020s\n",
      "Epoch: 5001 Accuracy: 0.7981 Loss: 1.10513186 time: 0.0020s\n",
      "Epoch: 6001 Accuracy: 0.7981 Loss: 1.10504043 time: 0.0020s\n",
      "Epoch: 7001 Accuracy: 0.7981 Loss: 1.10493684 time: 0.0030s\n",
      "Epoch: 8001 Accuracy: 0.7981 Loss: 1.10480046 time: 0.0020s\n",
      "Epoch: 9001 Accuracy: 0.7981 Loss: 1.10458183 time: 0.0040s\n",
      "Epoch: 10001 Accuracy: 0.7981 Loss: 1.10429716 time: 0.0040s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 23.5540s\n",
      "Epoch: 0001 Accuracy: 0.7981 Loss: 1.10429716 time: 0.0040s\n",
      "Epoch: 1001 Accuracy: 0.7981 Loss: 1.10429454 time: 0.0040s\n",
      "Epoch: 2001 Accuracy: 0.7981 Loss: 1.10429430 time: 0.0030s\n",
      "Epoch: 3001 Accuracy: 0.7981 Loss: 1.10429382 time: 0.0030s\n",
      "Epoch: 4001 Accuracy: 0.7981 Loss: 1.10429299 time: 0.0030s\n",
      "Epoch: 5001 Accuracy: 0.7981 Loss: 1.10429192 time: 0.0030s\n",
      "Epoch: 6001 Accuracy: 0.7981 Loss: 1.10428989 time: 0.0020s\n",
      "Epoch: 7001 Accuracy: 0.7981 Loss: 1.10428607 time: 0.0030s\n",
      "Epoch: 8001 Accuracy: 0.7981 Loss: 1.10427999 time: 0.0020s\n",
      "Epoch: 9001 Accuracy: 0.7981 Loss: 1.10426915 time: 0.0020s\n",
      "Epoch: 10001 Accuracy: 0.7981 Loss: 1.10126388 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 28.0198s\n",
      "Epoch: 0001 Accuracy: 0.7981 Loss: 1.10126388 time: 0.0020s\n",
      "Epoch: 1001 Accuracy: 0.8029 Loss: 1.10077477 time: 0.0030s\n",
      "Epoch: 2001 Accuracy: 0.8029 Loss: 1.10015011 time: 0.0030s\n",
      "Epoch: 3001 Accuracy: 0.8029 Loss: 1.09902012 time: 0.0020s\n",
      "Epoch: 4001 Accuracy: 0.8077 Loss: 1.09765267 time: 0.0020s\n",
      "Epoch: 5001 Accuracy: 0.8077 Loss: 1.09749591 time: 0.0020s\n",
      "Epoch: 6001 Accuracy: 0.8077 Loss: 1.09749591 time: 0.0030s\n",
      "Epoch: 7001 Accuracy: 0.8077 Loss: 1.09749591 time: 0.0020s\n",
      "Epoch: 8001 Accuracy: 0.8077 Loss: 1.09749591 time: 0.0020s\n",
      "Epoch: 9001 Accuracy: 0.8077 Loss: 1.09749591 time: 0.0030s\n",
      "Epoch: 10001 Accuracy: 0.8077 Loss: 1.09749591 time: 0.0019s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 22.3450s\n",
      "Epoch: 0001 Accuracy: 0.8077 Loss: 1.09749591 time: 0.0030s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1001 Accuracy: 0.8077 Loss: 1.09714913 time: 0.0020s\n",
      "Epoch: 2001 Accuracy: 0.8077 Loss: 1.09664798 time: 0.0030s\n",
      "Epoch: 3001 Accuracy: 0.8077 Loss: 1.09599125 time: 0.0018s\n",
      "Epoch: 4001 Accuracy: 0.8077 Loss: 1.09586728 time: 0.0030s\n",
      "Epoch: 5001 Accuracy: 0.8077 Loss: 1.09578371 time: 0.0020s\n",
      "Epoch: 6001 Accuracy: 0.8077 Loss: 1.09568763 time: 0.0020s\n",
      "Epoch: 7001 Accuracy: 0.8077 Loss: 1.09551001 time: 0.0020s\n",
      "Epoch: 8001 Accuracy: 0.8077 Loss: 1.09517157 time: 0.0020s\n",
      "Epoch: 9001 Accuracy: 0.8077 Loss: 1.09501672 time: 0.0020s\n",
      "Epoch: 10001 Accuracy: 0.8077 Loss: 1.09501672 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 20.0555s\n",
      "Epoch: 0001 Accuracy: 0.8077 Loss: 1.09501672 time: 0.0020s\n",
      "Epoch: 1001 Accuracy: 0.8077 Loss: 1.09500706 time: 0.0020s\n",
      "Epoch: 2001 Accuracy: 0.8077 Loss: 1.09498906 time: 0.0020s\n",
      "Epoch: 3001 Accuracy: 0.8077 Loss: 1.09495521 time: 0.0020s\n",
      "Epoch: 4001 Accuracy: 0.8077 Loss: 1.09490085 time: 0.0020s\n",
      "Epoch: 5001 Accuracy: 0.8077 Loss: 1.09482968 time: 0.0020s\n",
      "Epoch: 6001 Accuracy: 0.8077 Loss: 1.09475315 time: 0.0010s\n",
      "Epoch: 7001 Accuracy: 0.8077 Loss: 1.09466887 time: 0.0020s\n",
      "Epoch: 8001 Accuracy: 0.8077 Loss: 1.09460199 time: 0.0020s\n",
      "Epoch: 9001 Accuracy: 0.8077 Loss: 1.09460199 time: 0.0020s\n",
      "Epoch: 10001 Accuracy: 0.8077 Loss: 1.09460199 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 18.8305s\n",
      "Epoch: 0001 Accuracy: 0.8077 Loss: 1.09460199 time: 0.0020s\n",
      "Epoch: 1001 Accuracy: 0.8077 Loss: 1.09460044 time: 0.0020s\n",
      "Epoch: 2001 Accuracy: 0.8077 Loss: 1.09459674 time: 0.0020s\n",
      "Epoch: 3001 Accuracy: 0.8077 Loss: 1.09458983 time: 0.0020s\n",
      "Epoch: 4001 Accuracy: 0.8077 Loss: 1.09457922 time: 0.0020s\n",
      "Epoch: 5001 Accuracy: 0.8077 Loss: 1.09456611 time: 0.0020s\n",
      "Epoch: 6001 Accuracy: 0.8077 Loss: 1.09454966 time: 0.0030s\n",
      "Epoch: 7001 Accuracy: 0.8077 Loss: 1.09452808 time: 0.0030s\n",
      "Epoch: 8001 Accuracy: 0.8077 Loss: 1.09449732 time: 0.0020s\n",
      "Epoch: 9001 Accuracy: 0.8077 Loss: 1.09444904 time: 0.0024s\n",
      "Epoch: 10001 Accuracy: 0.8077 Loss: 1.09436393 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 23.7051s\n",
      "Epoch: 0001 Accuracy: 0.8077 Loss: 1.09436393 time: 0.0030s\n",
      "Epoch: 1001 Accuracy: 0.8077 Loss: 1.09436011 time: 0.0020s\n",
      "Epoch: 2001 Accuracy: 0.8077 Loss: 1.09435153 time: 0.0029s\n",
      "Epoch: 3001 Accuracy: 0.8077 Loss: 1.09433854 time: 0.0018s\n",
      "Epoch: 4001 Accuracy: 0.8077 Loss: 1.09432232 time: 0.0030s\n",
      "Epoch: 5001 Accuracy: 0.8077 Loss: 1.09430230 time: 0.0020s\n",
      "Epoch: 6001 Accuracy: 0.8077 Loss: 1.09427667 time: 0.0025s\n",
      "Epoch: 7001 Accuracy: 0.8077 Loss: 1.09424222 time: 0.0023s\n",
      "Epoch: 8001 Accuracy: 0.8077 Loss: 1.09418738 time: 0.0024s\n",
      "Epoch: 9001 Accuracy: 0.8077 Loss: 1.09408200 time: 0.0020s\n",
      "Epoch: 10001 Accuracy: 0.8077 Loss: 1.09364343 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 23.3873s\n",
      "Epoch: 0001 Accuracy: 0.8077 Loss: 1.09364343 time: 0.0030s\n",
      "Epoch: 1001 Accuracy: 0.8077 Loss: 1.09364319 time: 0.0020s\n",
      "Epoch: 2001 Accuracy: 0.8077 Loss: 1.09364223 time: 0.0020s\n",
      "Epoch: 3001 Accuracy: 0.8077 Loss: 1.09364092 time: 0.0020s\n",
      "Epoch: 4001 Accuracy: 0.8077 Loss: 1.09363854 time: 0.0024s\n",
      "Epoch: 5001 Accuracy: 0.8077 Loss: 1.09363544 time: 0.0022s\n",
      "Epoch: 6001 Accuracy: 0.8077 Loss: 1.09363127 time: 0.0023s\n",
      "Epoch: 7001 Accuracy: 0.8077 Loss: 1.09362650 time: 0.0020s\n",
      "Epoch: 8001 Accuracy: 0.8077 Loss: 1.09361970 time: 0.0021s\n",
      "Epoch: 9001 Accuracy: 0.8077 Loss: 1.09361112 time: 0.0020s\n",
      "Epoch: 10001 Accuracy: 0.8077 Loss: 1.09359622 time: 0.0022s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 22.1309s\n",
      "Epoch: 0001 Accuracy: 0.8077 Loss: 1.09359622 time: 0.0030s\n",
      "Epoch: 1001 Accuracy: 0.8077 Loss: 1.09359586 time: 0.0030s\n",
      "Epoch: 2001 Accuracy: 0.8077 Loss: 1.09359550 time: 0.0025s\n",
      "Epoch: 3001 Accuracy: 0.8077 Loss: 1.09359503 time: 0.0030s\n",
      "Epoch: 4001 Accuracy: 0.8077 Loss: 1.09359443 time: 0.0021s\n",
      "Epoch: 5001 Accuracy: 0.8077 Loss: 1.09359348 time: 0.0020s\n",
      "Epoch: 6001 Accuracy: 0.8077 Loss: 1.09359252 time: 0.0030s\n",
      "Epoch: 7001 Accuracy: 0.8077 Loss: 1.09359086 time: 0.0030s\n",
      "Epoch: 8001 Accuracy: 0.8077 Loss: 1.09358835 time: 0.0026s\n",
      "Epoch: 9001 Accuracy: 0.8077 Loss: 1.09358418 time: 0.0030s\n",
      "Epoch: 10001 Accuracy: 0.8077 Loss: 1.09357655 time: 0.0022s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 23.1352s\n",
      "Epoch: 0001 Accuracy: 0.8077 Loss: 1.09357655 time: 0.0030s\n",
      "Epoch: 1001 Accuracy: 0.8077 Loss: 1.09357584 time: 0.0030s\n",
      "Epoch: 2001 Accuracy: 0.8077 Loss: 1.09357560 time: 0.0020s\n",
      "Epoch: 3001 Accuracy: 0.8077 Loss: 1.09357536 time: 0.0020s\n",
      "Epoch: 4001 Accuracy: 0.8077 Loss: 1.09357500 time: 0.0020s\n",
      "Epoch: 5001 Accuracy: 0.8077 Loss: 1.09357440 time: 0.0024s\n",
      "Epoch: 6001 Accuracy: 0.8077 Loss: 1.09357369 time: 0.0030s\n",
      "Epoch: 7001 Accuracy: 0.8077 Loss: 1.09357262 time: 0.0030s\n",
      "Epoch: 8001 Accuracy: 0.8077 Loss: 1.09357107 time: 0.0026s\n",
      "Epoch: 9001 Accuracy: 0.8077 Loss: 1.09356868 time: 0.0030s\n",
      "Epoch: 10001 Accuracy: 0.8077 Loss: 1.09356380 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 23.2345s\n",
      "Epoch: 0001 Accuracy: 0.8077 Loss: 1.09356380 time: 0.0030s\n",
      "Epoch: 1001 Accuracy: 0.8077 Loss: 1.09356380 time: 0.0020s\n",
      "Epoch: 2001 Accuracy: 0.8077 Loss: 1.09356380 time: 0.0022s\n",
      "Epoch: 3001 Accuracy: 0.8077 Loss: 1.09356356 time: 0.0030s\n",
      "Epoch: 4001 Accuracy: 0.8077 Loss: 1.09356332 time: 0.0020s\n",
      "Epoch: 5001 Accuracy: 0.8077 Loss: 1.09356296 time: 0.0021s\n",
      "Epoch: 6001 Accuracy: 0.8077 Loss: 1.09356248 time: 0.0020s\n",
      "Epoch: 7001 Accuracy: 0.8077 Loss: 1.09356189 time: 0.0020s\n",
      "Epoch: 8001 Accuracy: 0.8077 Loss: 1.09356081 time: 0.0030s\n",
      "Epoch: 9001 Accuracy: 0.8077 Loss: 1.09355915 time: 0.0020s\n",
      "Epoch: 10001 Accuracy: 0.8077 Loss: 1.09355605 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 22.4461s\n",
      "Epoch: 0001 Accuracy: 0.8077 Loss: 1.09355605 time: 0.0030s\n",
      "Epoch: 1001 Accuracy: 0.8077 Loss: 1.09355605 time: 0.0030s\n",
      "Epoch: 2001 Accuracy: 0.8077 Loss: 1.09355593 time: 0.0027s\n",
      "Epoch: 3001 Accuracy: 0.8077 Loss: 1.09355593 time: 0.0025s\n",
      "Epoch: 4001 Accuracy: 0.8077 Loss: 1.09355569 time: 0.0024s\n",
      "Epoch: 5001 Accuracy: 0.8077 Loss: 1.09355557 time: 0.0025s\n",
      "Epoch: 6001 Accuracy: 0.8077 Loss: 1.09355521 time: 0.0020s\n",
      "Epoch: 7001 Accuracy: 0.8077 Loss: 1.09355462 time: 0.0021s\n",
      "Epoch: 8001 Accuracy: 0.8077 Loss: 1.09355402 time: 0.0020s\n",
      "Epoch: 9001 Accuracy: 0.8077 Loss: 1.09355283 time: 0.0020s\n",
      "Epoch: 10001 Accuracy: 0.8077 Loss: 1.09355056 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 22.8276s\n",
      "Epoch: 0001 Accuracy: 0.8077 Loss: 1.09355056 time: 0.0020s\n",
      "Epoch: 1001 Accuracy: 0.8077 Loss: 1.09354997 time: 0.0030s\n",
      "Epoch: 2001 Accuracy: 0.8077 Loss: 1.09354997 time: 0.0020s\n",
      "Epoch: 3001 Accuracy: 0.8077 Loss: 1.09354985 time: 0.0020s\n",
      "Epoch: 4001 Accuracy: 0.8077 Loss: 1.09354973 time: 0.0020s\n",
      "Epoch: 5001 Accuracy: 0.8077 Loss: 1.09354961 time: 0.0021s\n",
      "Epoch: 6001 Accuracy: 0.8077 Loss: 1.09354937 time: 0.0030s\n",
      "Epoch: 7001 Accuracy: 0.8077 Loss: 1.09354901 time: 0.0023s\n",
      "Epoch: 8001 Accuracy: 0.8077 Loss: 1.09354854 time: 0.0030s\n",
      "Epoch: 9001 Accuracy: 0.8077 Loss: 1.09354770 time: 0.0021s\n",
      "Epoch: 10001 Accuracy: 0.8077 Loss: 1.09354615 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 22.5566s\n",
      "Epoch: 0001 Accuracy: 0.8077 Loss: 1.09354615 time: 0.0030s\n",
      "Epoch: 1001 Accuracy: 0.8077 Loss: 1.09354615 time: 0.0030s\n",
      "Epoch: 2001 Accuracy: 0.8077 Loss: 1.09354615 time: 0.0026s\n",
      "Epoch: 3001 Accuracy: 0.8077 Loss: 1.09354615 time: 0.0020s\n",
      "Epoch: 4001 Accuracy: 0.8077 Loss: 1.09354603 time: 0.0030s\n",
      "Epoch: 5001 Accuracy: 0.8077 Loss: 1.09354591 time: 0.0023s\n",
      "Epoch: 6001 Accuracy: 0.8077 Loss: 1.09354568 time: 0.0020s\n",
      "Epoch: 7001 Accuracy: 0.8077 Loss: 1.09354544 time: 0.0030s\n",
      "Epoch: 8001 Accuracy: 0.8077 Loss: 1.09354508 time: 0.0030s\n",
      "Epoch: 9001 Accuracy: 0.8077 Loss: 1.09354448 time: 0.0030s\n",
      "Epoch: 10001 Accuracy: 0.8077 Loss: 1.09354317 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 22.2893s\n",
      "Epoch: 0001 Accuracy: 0.8077 Loss: 1.09354317 time: 0.0030s\n",
      "Epoch: 1001 Accuracy: 0.8077 Loss: 1.09354317 time: 0.0020s\n",
      "Epoch: 2001 Accuracy: 0.8077 Loss: 1.09354317 time: 0.0030s\n",
      "Epoch: 3001 Accuracy: 0.8077 Loss: 1.09354317 time: 0.0030s\n",
      "Epoch: 4001 Accuracy: 0.8077 Loss: 1.09354317 time: 0.0030s\n",
      "Epoch: 5001 Accuracy: 0.8077 Loss: 1.09354293 time: 0.0024s\n",
      "Epoch: 6001 Accuracy: 0.8077 Loss: 1.09354281 time: 0.0022s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7001 Accuracy: 0.8077 Loss: 1.09354258 time: 0.0020s\n",
      "Epoch: 8001 Accuracy: 0.8077 Loss: 1.09354234 time: 0.0020s\n",
      "Epoch: 9001 Accuracy: 0.8077 Loss: 1.09354198 time: 0.0020s\n",
      "Epoch: 10001 Accuracy: 0.8077 Loss: 1.09354126 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 23.0682s\n",
      "Epoch: 0001 Accuracy: 0.8077 Loss: 1.09354126 time: 0.0030s\n",
      "Epoch: 1001 Accuracy: 0.8077 Loss: 1.09354103 time: 0.0020s\n",
      "Epoch: 2001 Accuracy: 0.8077 Loss: 1.09354091 time: 0.0023s\n",
      "Epoch: 3001 Accuracy: 0.8077 Loss: 1.09354091 time: 0.0024s\n",
      "Epoch: 4001 Accuracy: 0.8077 Loss: 1.09354091 time: 0.0022s\n",
      "Epoch: 5001 Accuracy: 0.8077 Loss: 1.09354079 time: 0.0020s\n",
      "Epoch: 6001 Accuracy: 0.8077 Loss: 1.09354067 time: 0.0030s\n",
      "Epoch: 7001 Accuracy: 0.8077 Loss: 1.09354043 time: 0.0030s\n",
      "Epoch: 8001 Accuracy: 0.8077 Loss: 1.09354043 time: 0.0029s\n",
      "Epoch: 9001 Accuracy: 0.8077 Loss: 1.09354007 time: 0.0024s\n",
      "Epoch: 10001 Accuracy: 0.8077 Loss: 1.09353936 time: 0.0025s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 22.2405s\n",
      "Epoch: 0001 Accuracy: 0.8077 Loss: 1.09353936 time: 0.0030s\n",
      "Epoch: 1001 Accuracy: 0.8077 Loss: 1.09353924 time: 0.0024s\n",
      "Epoch: 2001 Accuracy: 0.8077 Loss: 1.09353924 time: 0.0020s\n",
      "Epoch: 3001 Accuracy: 0.8077 Loss: 1.09353924 time: 0.0021s\n",
      "Epoch: 4001 Accuracy: 0.8077 Loss: 1.09353924 time: 0.0030s\n",
      "Epoch: 5001 Accuracy: 0.8077 Loss: 1.09353912 time: 0.0020s\n",
      "Epoch: 6001 Accuracy: 0.8077 Loss: 1.09353912 time: 0.0024s\n",
      "Epoch: 7001 Accuracy: 0.8077 Loss: 1.09353888 time: 0.0020s\n",
      "Epoch: 8001 Accuracy: 0.8077 Loss: 1.09353876 time: 0.0020s\n",
      "Epoch: 9001 Accuracy: 0.8077 Loss: 1.09353852 time: 0.0020s\n",
      "Epoch: 10001 Accuracy: 0.8077 Loss: 1.09353793 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 21.9483s\n",
      "Epoch: 0001 Accuracy: 0.8077 Loss: 1.09353793 time: 0.0030s\n",
      "Epoch: 1001 Accuracy: 0.8077 Loss: 1.09353781 time: 0.0030s\n",
      "Epoch: 2001 Accuracy: 0.8077 Loss: 1.09353781 time: 0.0030s\n",
      "Epoch: 3001 Accuracy: 0.8077 Loss: 1.09353781 time: 0.0020s\n",
      "Epoch: 4001 Accuracy: 0.8077 Loss: 1.09353781 time: 0.0018s\n",
      "Epoch: 5001 Accuracy: 0.8077 Loss: 1.09353781 time: 0.0020s\n",
      "Epoch: 6001 Accuracy: 0.8077 Loss: 1.09353769 time: 0.0030s\n",
      "Epoch: 7001 Accuracy: 0.8077 Loss: 1.09353757 time: 0.0022s\n",
      "Epoch: 8001 Accuracy: 0.8077 Loss: 1.09353757 time: 0.0030s\n",
      "Epoch: 9001 Accuracy: 0.8077 Loss: 1.09353721 time: 0.0028s\n",
      "Epoch: 10001 Accuracy: 0.8077 Loss: 1.09353685 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 22.9858s\n",
      "Epoch: 0001 Accuracy: 0.8077 Loss: 1.09353685 time: 0.0030s\n",
      "Epoch: 1001 Accuracy: 0.8077 Loss: 1.09353685 time: 0.0023s\n",
      "Epoch: 2001 Accuracy: 0.8077 Loss: 1.09353685 time: 0.0020s\n",
      "Epoch: 3001 Accuracy: 0.8077 Loss: 1.09353685 time: 0.0030s\n",
      "Epoch: 4001 Accuracy: 0.8077 Loss: 1.09353685 time: 0.0021s\n",
      "Epoch: 5001 Accuracy: 0.8077 Loss: 1.09353685 time: 0.0030s\n",
      "Epoch: 6001 Accuracy: 0.8077 Loss: 1.09353685 time: 0.0028s\n",
      "Epoch: 7001 Accuracy: 0.8077 Loss: 1.09353685 time: 0.0022s\n",
      "Epoch: 8001 Accuracy: 0.8077 Loss: 1.09353662 time: 0.0026s\n",
      "Epoch: 9001 Accuracy: 0.8077 Loss: 1.09353650 time: 0.0025s\n",
      "Epoch: 10001 Accuracy: 0.8077 Loss: 1.09353614 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 22.6227s\n",
      "Epoch: 0001 Accuracy: 0.8077 Loss: 1.09353614 time: 0.0030s\n",
      "Epoch: 1001 Accuracy: 0.8077 Loss: 1.09353590 time: 0.0021s\n",
      "Epoch: 2001 Accuracy: 0.8077 Loss: 1.09353590 time: 0.0022s\n",
      "Epoch: 3001 Accuracy: 0.8077 Loss: 1.09353590 time: 0.0020s\n",
      "Epoch: 4001 Accuracy: 0.8077 Loss: 1.09353590 time: 0.0020s\n",
      "Epoch: 5001 Accuracy: 0.8077 Loss: 1.09353578 time: 0.0020s\n",
      "Epoch: 6001 Accuracy: 0.8077 Loss: 1.09353578 time: 0.0020s\n",
      "Epoch: 7001 Accuracy: 0.8077 Loss: 1.09353578 time: 0.0020s\n",
      "Epoch: 8001 Accuracy: 0.8077 Loss: 1.09353578 time: 0.0021s\n",
      "Epoch: 9001 Accuracy: 0.8077 Loss: 1.09353554 time: 0.0020s\n",
      "Epoch: 10001 Accuracy: 0.8077 Loss: 1.09353530 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 21.3962s\n",
      "Epoch: 0001 Accuracy: 0.8077 Loss: 1.09353530 time: 0.0030s\n",
      "Epoch: 1001 Accuracy: 0.8077 Loss: 1.09353530 time: 0.0020s\n",
      "Epoch: 2001 Accuracy: 0.8077 Loss: 1.09353530 time: 0.0027s\n",
      "Epoch: 3001 Accuracy: 0.8077 Loss: 1.09353530 time: 0.0030s\n",
      "Epoch: 4001 Accuracy: 0.8077 Loss: 1.09353530 time: 0.0030s\n",
      "Epoch: 5001 Accuracy: 0.8077 Loss: 1.09353530 time: 0.0020s\n",
      "Epoch: 6001 Accuracy: 0.8077 Loss: 1.09353530 time: 0.0030s\n",
      "Epoch: 7001 Accuracy: 0.8077 Loss: 1.09353518 time: 0.0020s\n",
      "Epoch: 8001 Accuracy: 0.8077 Loss: 1.09353518 time: 0.0030s\n",
      "Epoch: 9001 Accuracy: 0.8077 Loss: 1.09353495 time: 0.0021s\n",
      "Epoch: 10001 Accuracy: 0.8077 Loss: 1.09353471 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 22.3812s\n",
      "Epoch: 0001 Accuracy: 0.8077 Loss: 1.09353471 time: 0.0040s\n",
      "Epoch: 1001 Accuracy: 0.8077 Loss: 1.09353471 time: 0.0020s\n",
      "Epoch: 2001 Accuracy: 0.8077 Loss: 1.09353471 time: 0.0030s\n",
      "Epoch: 3001 Accuracy: 0.8077 Loss: 1.09353471 time: 0.0025s\n",
      "Epoch: 4001 Accuracy: 0.8077 Loss: 1.09353471 time: 0.0032s\n",
      "Epoch: 5001 Accuracy: 0.8077 Loss: 1.09353459 time: 0.0024s\n",
      "Epoch: 6001 Accuracy: 0.8077 Loss: 1.09353459 time: 0.0026s\n",
      "Epoch: 7001 Accuracy: 0.8077 Loss: 1.09353459 time: 0.0029s\n",
      "Epoch: 8001 Accuracy: 0.8077 Loss: 1.09353459 time: 0.0030s\n",
      "Epoch: 9001 Accuracy: 0.8077 Loss: 1.09353447 time: 0.0030s\n",
      "Epoch: 10001 Accuracy: 0.8077 Loss: 1.09353423 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 22.5425s\n",
      "Epoch: 0001 Accuracy: 0.8077 Loss: 1.09353423 time: 0.0030s\n",
      "Epoch: 1001 Accuracy: 0.8077 Loss: 1.09353423 time: 0.0020s\n",
      "Epoch: 2001 Accuracy: 0.8077 Loss: 1.09353423 time: 0.0019s\n",
      "Epoch: 3001 Accuracy: 0.8077 Loss: 1.09353423 time: 0.0030s\n",
      "Epoch: 4001 Accuracy: 0.8077 Loss: 1.09353423 time: 0.0017s\n",
      "Epoch: 5001 Accuracy: 0.8077 Loss: 1.09353423 time: 0.0021s\n",
      "Epoch: 6001 Accuracy: 0.8077 Loss: 1.09353423 time: 0.0026s\n",
      "Epoch: 7001 Accuracy: 0.8077 Loss: 1.09353423 time: 0.0030s\n",
      "Epoch: 8001 Accuracy: 0.8077 Loss: 1.09353411 time: 0.0020s\n",
      "Epoch: 9001 Accuracy: 0.8077 Loss: 1.09353411 time: 0.0020s\n",
      "Epoch: 10001 Accuracy: 0.8077 Loss: 1.09353399 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 21.9051s\n",
      "Epoch: 0001 Accuracy: 0.8077 Loss: 1.09353399 time: 0.0030s\n",
      "Epoch: 1001 Accuracy: 0.8077 Loss: 1.09353399 time: 0.0030s\n",
      "Epoch: 2001 Accuracy: 0.8077 Loss: 1.09353399 time: 0.0020s\n",
      "Epoch: 3001 Accuracy: 0.8077 Loss: 1.09353399 time: 0.0024s\n",
      "Epoch: 4001 Accuracy: 0.8077 Loss: 1.09353399 time: 0.0030s\n",
      "Epoch: 5001 Accuracy: 0.8077 Loss: 1.09353399 time: 0.0030s\n",
      "Epoch: 6001 Accuracy: 0.8077 Loss: 1.09353399 time: 0.0030s\n",
      "Epoch: 7001 Accuracy: 0.8077 Loss: 1.09353399 time: 0.0024s\n",
      "Epoch: 8001 Accuracy: 0.8077 Loss: 1.09353399 time: 0.0023s\n",
      "Epoch: 9001 Accuracy: 0.8077 Loss: 1.09353387 time: 0.0023s\n",
      "Epoch: 10001 Accuracy: 0.8077 Loss: 1.09353387 time: 0.0023s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 22.9241s\n",
      "Epoch: 0001 Accuracy: 0.8077 Loss: 1.09353387 time: 0.0030s\n",
      "Epoch: 1001 Accuracy: 0.8077 Loss: 1.09353387 time: 0.0020s\n",
      "Epoch: 2001 Accuracy: 0.8077 Loss: 1.09353387 time: 0.0019s\n",
      "Epoch: 3001 Accuracy: 0.8077 Loss: 1.09353387 time: 0.0020s\n",
      "Epoch: 4001 Accuracy: 0.8077 Loss: 1.09353387 time: 0.0019s\n",
      "Epoch: 5001 Accuracy: 0.8077 Loss: 1.09353387 time: 0.0021s\n",
      "Epoch: 6001 Accuracy: 0.8077 Loss: 1.09353387 time: 0.0020s\n",
      "Epoch: 7001 Accuracy: 0.8077 Loss: 1.09353387 time: 0.0019s\n",
      "Epoch: 8001 Accuracy: 0.8077 Loss: 1.09353387 time: 0.0030s\n",
      "Epoch: 9001 Accuracy: 0.8077 Loss: 1.09353387 time: 0.0030s\n",
      "Epoch: 10001 Accuracy: 0.8077 Loss: 1.09353387 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 22.1686s\n"
     ]
    }
   ],
   "source": [
    "mask_percentage = [1.]\n",
    "\n",
    "for m in mask_percentage:\n",
    "    \n",
    "    #features = np.expand_dims(feature, axis=0)\n",
    "    #print(features.shape)\n",
    "    \n",
    "    # Masking\n",
    "    number_of_rows = features[0].shape[0]\n",
    "    random_indices = np.random.choice(number_of_rows, size=int(m*number_of_rows), replace=False)\n",
    "    \n",
    "    # exclude low activity areas from masking\n",
    "    zip_sum = data.groupby(by='origin', as_index=False).sum()\n",
    "    low_act = zip_sum[zip_sum.weight < 3000].index\n",
    "    \n",
    "    random_indices = np.setdiff1d(random_indices, low_act)\n",
    "    random_rows = features[0][random_indices, :]\n",
    "    features[0][random_indices, :] = np.tile(np.array([[0.2]]),random_rows.shape)\n",
    "    \n",
    "    \n",
    "    print(\"\\nMasked {}% of nodes\\n\".format(int(m*100)))\n",
    "    prev_loss, op = train(adj,features,labels, random_indices, True)\n",
    "    #print(op)\n",
    "    loss, op = train(adj,op.cpu().detach().numpy(),labels, random_indices)\n",
    "    while loss < prev_loss :\n",
    "        prev_loss = loss\n",
    "        loss, op = train(adj,op.cpu().detach().numpy(),labels, random_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
