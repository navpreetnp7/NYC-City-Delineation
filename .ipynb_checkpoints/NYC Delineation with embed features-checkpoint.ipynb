{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin</th>\n",
       "      <th>destination</th>\n",
       "      <th>weight</th>\n",
       "      <th>initialFeat</th>\n",
       "      <th>true_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11436</td>\n",
       "      <td>10009</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11436</td>\n",
       "      <td>10011</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11436</td>\n",
       "      <td>10013</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11436</td>\n",
       "      <td>10019</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11436</td>\n",
       "      <td>10021</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   origin  destination  weight  initialFeat  true_label\n",
       "0   11436        10009       1          4.0           4\n",
       "1   11436        10011       1          4.0           4\n",
       "2   11436        10013       1          4.0           4\n",
       "3   11436        10019       1          4.0           4\n",
       "4   11436        10021       1          4.0           4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/zips_merged.csv', delimiter=',')\n",
    "data = data.rename(columns={'total': 'weight', 'w_zip':'origin', 'h_zip':'destination'})\n",
    "data = data[data.destination.isin(data.origin.unique())]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "populationByAge = pd.read_csv('data/zicode_populationByAge.csv', delimiter=',')\n",
    "populationByAge = populationByAge.iloc[:,0:2]\n",
    "populationByAge.rename(columns={'ZIPCODE':'destination'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "housePrice = pd.read_csv('data/zipcode_housePrice.csv', delimiter=',')\n",
    "weights = [5000,12500,17500,22500,27500,32500,37500,45000,55000,65000,75000,85000\n",
    "                    ,95000,112500,137500,162500,187500,225000,275000,350000,450000,625000,875000\n",
    "                        ,1250000,1750000,2000000]\n",
    "for i in range(len(weights)):\n",
    "    housePrice.iloc[i,2:] = housePrice.iloc[i,2:]*weights[i]\n",
    "housePrice.iloc[:,1] [housePrice.iloc[:,1] == 0] = 1\n",
    "\n",
    "tmp = (housePrice.iloc[:,2:] != 0 ).sum(axis=1)\n",
    "tmp[tmp == 0] = 1\n",
    "housePrice = pd.concat([housePrice.iloc[:,0],housePrice.iloc[:,2:].sum(axis=1) / tmp ], axis = 1 )\n",
    "housePrice.rename(columns={'ZIPCODE':'destination'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = pd.read_csv('data/zips_area.csv', delimiter=',')\n",
    "area = area.iloc[:,:2]\n",
    "area.rename(columns={'ZIPCODE':'destination'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "income = pd.read_csv('data/zipcode_income.csv', delimiter=',')\n",
    "income = income.iloc[:,:2]\n",
    "income[income.isna()] = 0\n",
    "income.rename(columns={'ZIPCODE':'destination'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "populationJobs = pd.read_csv('data/zipcode_population_Jobs.csv', delimiter=',')\n",
    "populationJobs = populationJobs.iloc[:,:2]\n",
    "populationJobs.rename(columns={'ZIPCODE':'destination'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(populationByAge)\n",
    "data = data.merge(housePrice)\n",
    "data = data.merge(area)\n",
    "data = data.merge(income)\n",
    "data = data.merge(populationJobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[:,5:]=(data.iloc[:,5:]-data.iloc[:,5:].min())/(data.iloc[:,5:].max()-data.iloc[:,5:].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin</th>\n",
       "      <th>destination</th>\n",
       "      <th>weight</th>\n",
       "      <th>initialFeat</th>\n",
       "      <th>true_label</th>\n",
       "      <th>Estimate!!Total!!Total population</th>\n",
       "      <th>0</th>\n",
       "      <th>AREA</th>\n",
       "      <th>median_familyIncome(USD)</th>\n",
       "      <th>totalJobs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11436</td>\n",
       "      <td>10009</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.300165</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.032183</td>\n",
       "      <td>0.243977</td>\n",
       "      <td>0.042630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11213</td>\n",
       "      <td>10009</td>\n",
       "      <td>14</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.300165</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.032183</td>\n",
       "      <td>0.243977</td>\n",
       "      <td>0.042630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11212</td>\n",
       "      <td>10009</td>\n",
       "      <td>27</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.300165</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.032183</td>\n",
       "      <td>0.243977</td>\n",
       "      <td>0.042630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11225</td>\n",
       "      <td>10009</td>\n",
       "      <td>26</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.300165</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.032183</td>\n",
       "      <td>0.243977</td>\n",
       "      <td>0.042630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11218</td>\n",
       "      <td>10009</td>\n",
       "      <td>60</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.300165</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.032183</td>\n",
       "      <td>0.243977</td>\n",
       "      <td>0.042630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36407</th>\n",
       "      <td>11211</td>\n",
       "      <td>11371</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36408</th>\n",
       "      <td>11373</td>\n",
       "      <td>11371</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36409</th>\n",
       "      <td>10168</td>\n",
       "      <td>11371</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36410</th>\n",
       "      <td>10278</td>\n",
       "      <td>11371</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36411</th>\n",
       "      <td>10036</td>\n",
       "      <td>11371</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36412 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       origin  destination  weight  initialFeat  true_label  \\\n",
       "0       11436        10009       1          4.0           4   \n",
       "1       11213        10009      14          3.0           3   \n",
       "2       11212        10009      27          3.0           3   \n",
       "3       11225        10009      26          3.0           3   \n",
       "4       11218        10009      60          3.0           3   \n",
       "...       ...          ...     ...          ...         ...   \n",
       "36407   11211        11371       7          1.0           3   \n",
       "36408   11373        11371       3          4.0           4   \n",
       "36409   10168        11371       1          1.0           1   \n",
       "36410   10278        11371       1          1.0           1   \n",
       "36411   10036        11371       5          1.0           1   \n",
       "\n",
       "       Estimate!!Total!!Total population         0      AREA  \\\n",
       "0                               0.300165  0.005332  0.032183   \n",
       "1                               0.300165  0.005332  0.032183   \n",
       "2                               0.300165  0.005332  0.032183   \n",
       "3                               0.300165  0.005332  0.032183   \n",
       "4                               0.300165  0.005332  0.032183   \n",
       "...                                  ...       ...       ...   \n",
       "36407                           0.000000  0.000000  0.063146   \n",
       "36408                           0.000000  0.000000  0.063146   \n",
       "36409                           0.000000  0.000000  0.063146   \n",
       "36410                           0.000000  0.000000  0.063146   \n",
       "36411                           0.000000  0.000000  0.063146   \n",
       "\n",
       "       median_familyIncome(USD)  totalJobs  \n",
       "0                      0.243977   0.042630  \n",
       "1                      0.243977   0.042630  \n",
       "2                      0.243977   0.042630  \n",
       "3                      0.243977   0.042630  \n",
       "4                      0.243977   0.042630  \n",
       "...                         ...        ...  \n",
       "36407                  0.000000   0.050874  \n",
       "36408                  0.000000   0.050874  \n",
       "36409                  0.000000   0.050874  \n",
       "36410                  0.000000   0.050874  \n",
       "36411                  0.000000   0.050874  \n",
       "\n",
       "[36412 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "weight_decay = 10e-4\n",
    "epochs = 10001\n",
    "seed = 165\n",
    "hidden = 10\n",
    "lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(adj):\n",
    "\n",
    "    adj = torch.FloatTensor(adj)\n",
    "    adj_id = torch.FloatTensor(torch.eye(adj.shape[1]))\n",
    "    adj_id = adj_id.reshape((1, adj.shape[1], adj.shape[1]))\n",
    "    adj_id = adj_id.repeat(adj.shape[0], 1, 1)\n",
    "    adj = adj + adj_id\n",
    "    rowsum = torch.FloatTensor(adj.sum(2))\n",
    "    degree_mat_inv_sqrt = torch.diag_embed(torch.float_power(rowsum,-0.5), dim1=-2, dim2=-1).float()\n",
    "    adj_norm = torch.bmm(torch.transpose(torch.bmm(adj,degree_mat_inv_sqrt),1,2),degree_mat_inv_sqrt)\n",
    "\n",
    "    return adj_norm\n",
    "\n",
    "\n",
    "def doublerelu(x):\n",
    "    return torch.clamp(x, 0, 1)\n",
    "\n",
    "class GNN1Layer(Module):\n",
    "\n",
    "    def __init__(self, batch_size, in_features, out_features, first):\n",
    "        super(GNN1Layer, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        weight1_eye = torch.FloatTensor(torch.eye(in_features, out_features))\n",
    "        weight1_eye = weight1_eye.reshape((1, in_features, out_features))\n",
    "        weight1_eye = weight1_eye.repeat(batch_size, 1, 1)\n",
    "        self.weight1 = Parameter(weight1_eye)\n",
    "        if not first:\n",
    "            self.weight2 = Parameter(torch.zeros(batch_size, in_features, out_features))\n",
    "        else:\n",
    "            self.weight2 = Parameter(torch.empty(batch_size, in_features, out_features))\n",
    "            nn.init.kaiming_normal_(self.weight2, mode='fan_out')\n",
    "\n",
    "    def forward(self, input, adj):\n",
    "        v1 = torch.bmm(input, self.weight1)\n",
    "        v2 = torch.bmm(torch.bmm(adj, input), self.weight2)\n",
    "        output = v1 + v2\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN1(nn.Module):\n",
    "\n",
    "    def __init__(self, batch_size, nfeat, ndim, hidden, first):\n",
    "        super(GNN1, self).__init__()\n",
    "\n",
    "        self.gc1 = GNN1Layer(batch_size, nfeat, ndim, first)\n",
    "\n",
    "    def forward(self, x, adj, random_indices):\n",
    "        f = torch.clone(x)\n",
    "        x = doublerelu(self.gc1(x, adj))\n",
    "        x = x/x.sum(axis=2).unsqueeze(2) #normalize st sum = 1\n",
    "\n",
    "        f[0][random_indices, :x.shape[2]] = x[0][random_indices, :]\n",
    "        \n",
    "        return f[:,:,:x.shape[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(adj,features,labels,random_indices,first=False):\n",
    "    \n",
    "    adj_norm = normalize(adj)\n",
    "    \n",
    "    labels = labels - 1\n",
    "    \n",
    "    adj = torch.FloatTensor(adj)\n",
    "    adj_norm = torch.FloatTensor(adj_norm)\n",
    "    features = torch.FloatTensor(features)\n",
    "    labels = torch.FloatTensor(labels)\n",
    "    \n",
    "    model = GNN1(batch_size=adj.shape[0],\n",
    "                nfeat=features.shape[-1],\n",
    "                ndim=nb_label,\n",
    "                hidden=hidden,\n",
    "                first=first)\n",
    "    if cuda:\n",
    "        model.cuda()\n",
    "        features = features.cuda()\n",
    "        adj = adj.cuda()\n",
    "        adj_norm = adj_norm.cuda()\n",
    "        labels = labels.cuda()\n",
    "    \n",
    "    # Train model\n",
    "    t_total = time.time()\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(),\n",
    "                           lr=lr, weight_decay=weight_decay)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        t = time.time()\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(features, adj_norm, random_indices)\n",
    "            \n",
    "        accuracy = torch.sum(torch.argmax(output,axis=2)==labels.reshape(1,-1))/labels.shape[0]\n",
    "        \n",
    "        loss = criterion(output[0],labels.reshape(-1).long())\n",
    "\n",
    "        loss.backward(retain_graph=True)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch == 0:\n",
    "            best_loss = loss\n",
    "            best_output = output\n",
    "            best_acc = accuracy\n",
    "        else:\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "                best_output = output\n",
    "                best_acc = accuracy\n",
    "\n",
    "        if epoch % 1000 == 0:\n",
    "            print('Epoch: {:04d}'.format(epoch + 1),\n",
    "                  'Accuracy: {:.4f}'.format(best_acc.item()),\n",
    "                  'Loss: {:.8f}'.format(best_loss.item()),\n",
    "                  'time: {:.4f}s'.format(time.time() - t))\n",
    "            \n",
    "    print(\"Optimization Finished!\")\n",
    "    print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
    "    \n",
    "    return best_loss,best_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svdApprox(adj, dim, relu=False):\n",
    "    adj = torch.FloatTensor(adj[0])\n",
    "    U, S, Vh = torch.linalg.svd(adj)\n",
    "    mu = torch.matmul(torch.matmul(U[:, :dim], torch.diag(S[:dim])), Vh[:dim, :])\n",
    "\n",
    "    embedx = torch.matmul(U[:, :dim], torch.diag(torch.pow(S[:dim], 0.5)))\n",
    "    embedy = torch.transpose(torch.matmul(torch.diag(torch.pow(S[:dim], 0.5)), Vh[:dim, :]), 0, 1)\n",
    "\n",
    "    return embedx, embedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "\n",
    "    G = nx.from_pandas_edgelist(data, 'origin', 'destination', 'weight',create_using=nx.DiGraph())\n",
    "    adj_list = np.array([nx.adjacency_matrix(G).todense()], dtype=float)\n",
    "    #init_feat = np.array(data.groupby('origin')['initialFeat'].agg(['unique']))\n",
    "    \n",
    "    init_feat1 = np.array(data.groupby('origin')['Estimate!!Total!!Total population'].agg(['unique']))\n",
    "    init_feat1 = np.array(list(map(lambda x: x[0][0], init_feat1))).reshape(-1, 1)\n",
    "    init_feat2 = np.array(data.groupby('origin')[0].agg(['unique']))\n",
    "    init_feat2 = np.array(list(map(lambda x: x[0][0], init_feat2))).reshape(-1, 1)\n",
    "    init_feat3 = np.array(data.groupby('origin')['AREA'].agg(['unique']))\n",
    "    init_feat3 = np.array(list(map(lambda x: x[0][0], init_feat3))).reshape(-1, 1)\n",
    "    init_feat4 = np.array(data.groupby('origin')['median_familyIncome(USD)'].agg(['unique']))\n",
    "    init_feat4 = np.array(list(map(lambda x: x[0][0], init_feat4))).reshape(-1, 1)\n",
    "    init_feat5 = np.array(data.groupby('origin')['totalJobs'].agg(['unique']))\n",
    "    init_feat5 = np.array(list(map(lambda x: x[0][0], init_feat5))).reshape(-1, 1)\n",
    "    \n",
    "    init_feat = np.concatenate([init_feat1,init_feat2,init_feat3,init_feat4,init_feat5],axis=1)\n",
    "    \n",
    "    true_label = np.array(data.groupby('origin')['true_label'].agg(['unique']))\n",
    "    \n",
    "    true_label = np.array(list(map(lambda x: x[0][0], true_label))).reshape(-1, 1)\n",
    "    return adj_list,init_feat,true_label\n",
    "\n",
    "adj,feature,labels = load_data()\n",
    "\n",
    "features = np.expand_dims(feature, axis=0)\n",
    "\n",
    "#feature = feature - 1\n",
    "#nb_label = int(max(feature)) + 1\n",
    "#featuress = np.eye(nb_label)[np.array(feature,dtype=int).reshape(1,-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_feat = np.array(data.groupby('origin')['initialFeat'].agg(['unique']))\n",
    "init_feat = np.array(list(map(lambda x: x[0][0], init_feat))).reshape(-1, 1)\n",
    "init_feat = init_feat - 1\n",
    "nb_label = int(max(init_feat)) + 1\n",
    "\n",
    "init_feat = np.eye(nb_label)[np.array(init_feat,dtype=int).reshape(1,-1)]\n",
    "features = np.concatenate([init_feat, features],axis=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Masked 100% of nodes\n",
      "\n",
      "Epoch: 0001 Accuracy: 0.4519 Loss: 1.41599774 time: 0.4508s\n",
      "Epoch: 1001 Accuracy: 0.5337 Loss: 1.35931265 time: 0.0020s\n",
      "Epoch: 2001 Accuracy: 0.5433 Loss: 1.35605979 time: 0.0030s\n",
      "Epoch: 3001 Accuracy: 0.5481 Loss: 1.34696519 time: 0.0030s\n",
      "Epoch: 4001 Accuracy: 0.5481 Loss: 1.34251797 time: 0.0020s\n",
      "Epoch: 5001 Accuracy: 0.5577 Loss: 1.33225071 time: 0.0020s\n",
      "Epoch: 6001 Accuracy: 0.5577 Loss: 1.33225071 time: 0.0030s\n",
      "Epoch: 7001 Accuracy: 0.5577 Loss: 1.33225071 time: 0.0020s\n",
      "Epoch: 8001 Accuracy: 0.5577 Loss: 1.33225071 time: 0.0020s\n",
      "Epoch: 9001 Accuracy: 0.5577 Loss: 1.33225071 time: 0.0030s\n",
      "Epoch: 10001 Accuracy: 0.5577 Loss: 1.33225071 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 21.7050s\n",
      "Epoch: 0001 Accuracy: 0.5577 Loss: 1.33225071 time: 0.0030s\n",
      "Epoch: 1001 Accuracy: 0.5673 Loss: 1.32374191 time: 0.0030s\n",
      "Epoch: 2001 Accuracy: 0.5721 Loss: 1.31283772 time: 0.0020s\n",
      "Epoch: 3001 Accuracy: 0.5769 Loss: 1.30120575 time: 0.0020s\n",
      "Epoch: 4001 Accuracy: 0.5865 Loss: 1.29459870 time: 0.0020s\n",
      "Epoch: 5001 Accuracy: 0.5865 Loss: 1.29459870 time: 0.0020s\n",
      "Epoch: 6001 Accuracy: 0.5865 Loss: 1.29459870 time: 0.0020s\n",
      "Epoch: 7001 Accuracy: 0.5865 Loss: 1.29459870 time: 0.0020s\n",
      "Epoch: 8001 Accuracy: 0.5865 Loss: 1.29459870 time: 0.0020s\n",
      "Epoch: 9001 Accuracy: 0.5865 Loss: 1.29459870 time: 0.0020s\n",
      "Epoch: 10001 Accuracy: 0.5865 Loss: 1.29459870 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 21.6680s\n",
      "Epoch: 0001 Accuracy: 0.5865 Loss: 1.29459870 time: 0.0030s\n",
      "Epoch: 1001 Accuracy: 0.5962 Loss: 1.28671181 time: 0.0030s\n",
      "Epoch: 2001 Accuracy: 0.6202 Loss: 1.27439249 time: 0.0030s\n",
      "Epoch: 3001 Accuracy: 0.6250 Loss: 1.27159107 time: 0.0030s\n",
      "Epoch: 4001 Accuracy: 0.6250 Loss: 1.27159107 time: 0.0020s\n",
      "Epoch: 5001 Accuracy: 0.6250 Loss: 1.27159107 time: 0.0030s\n",
      "Epoch: 6001 Accuracy: 0.6250 Loss: 1.27159107 time: 0.0020s\n",
      "Epoch: 7001 Accuracy: 0.6250 Loss: 1.27159107 time: 0.0020s\n",
      "Epoch: 8001 Accuracy: 0.6250 Loss: 1.27159107 time: 0.0020s\n",
      "Epoch: 9001 Accuracy: 0.6250 Loss: 1.27159107 time: 0.0020s\n",
      "Epoch: 10001 Accuracy: 0.6250 Loss: 1.27159107 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 24.1574s\n",
      "Epoch: 0001 Accuracy: 0.6250 Loss: 1.27159107 time: 0.0030s\n",
      "Epoch: 1001 Accuracy: 0.6298 Loss: 1.26665235 time: 0.0020s\n",
      "Epoch: 2001 Accuracy: 0.6298 Loss: 1.26215029 time: 0.0030s\n",
      "Epoch: 3001 Accuracy: 0.6298 Loss: 1.25593579 time: 0.0020s\n",
      "Epoch: 4001 Accuracy: 0.6394 Loss: 1.24724269 time: 0.0020s\n",
      "Epoch: 5001 Accuracy: 0.6538 Loss: 1.23853385 time: 0.0030s\n",
      "Epoch: 6001 Accuracy: 0.6683 Loss: 1.22866964 time: 0.0030s\n",
      "Epoch: 7001 Accuracy: 0.6683 Loss: 1.22866964 time: 0.0020s\n",
      "Epoch: 8001 Accuracy: 0.6683 Loss: 1.22866964 time: 0.0020s\n",
      "Epoch: 9001 Accuracy: 0.6683 Loss: 1.22866964 time: 0.0030s\n",
      "Epoch: 10001 Accuracy: 0.6683 Loss: 1.22866964 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 23.8799s\n",
      "Epoch: 0001 Accuracy: 0.6683 Loss: 1.22866964 time: 0.0030s\n",
      "Epoch: 1001 Accuracy: 0.6683 Loss: 1.22505796 time: 0.0030s\n",
      "Epoch: 2001 Accuracy: 0.6731 Loss: 1.22306108 time: 0.0030s\n",
      "Epoch: 3001 Accuracy: 0.6827 Loss: 1.22119987 time: 0.0030s\n",
      "Epoch: 4001 Accuracy: 0.6827 Loss: 1.21831095 time: 0.0030s\n",
      "Epoch: 5001 Accuracy: 0.6875 Loss: 1.21614790 time: 0.0030s\n",
      "Epoch: 6001 Accuracy: 0.6779 Loss: 1.21197391 time: 0.0030s\n",
      "Epoch: 7001 Accuracy: 0.6923 Loss: 1.20613790 time: 0.0030s\n",
      "Epoch: 8001 Accuracy: 0.6923 Loss: 1.20613790 time: 0.0030s\n",
      "Epoch: 9001 Accuracy: 0.6923 Loss: 1.20613790 time: 0.0030s\n",
      "Epoch: 10001 Accuracy: 0.6923 Loss: 1.20613790 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 24.1213s\n",
      "Epoch: 0001 Accuracy: 0.6923 Loss: 1.20613790 time: 0.0030s\n",
      "Epoch: 1001 Accuracy: 0.6971 Loss: 1.20533895 time: 0.0020s\n",
      "Epoch: 2001 Accuracy: 0.6971 Loss: 1.20450604 time: 0.0030s\n",
      "Epoch: 3001 Accuracy: 0.6923 Loss: 1.20370603 time: 0.0020s\n",
      "Epoch: 4001 Accuracy: 0.6875 Loss: 1.20280480 time: 0.0030s\n",
      "Epoch: 5001 Accuracy: 0.6875 Loss: 1.20176315 time: 0.0020s\n",
      "Epoch: 6001 Accuracy: 0.6875 Loss: 1.20051515 time: 0.0030s\n",
      "Epoch: 7001 Accuracy: 0.6923 Loss: 1.19765306 time: 0.0030s\n",
      "Epoch: 8001 Accuracy: 0.6971 Loss: 1.19616258 time: 0.0020s\n",
      "Epoch: 9001 Accuracy: 0.6971 Loss: 1.19616258 time: 0.0030s\n",
      "Epoch: 10001 Accuracy: 0.6971 Loss: 1.19616258 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 24.3200s\n",
      "Epoch: 0001 Accuracy: 0.6971 Loss: 1.19616258 time: 0.0040s\n",
      "Epoch: 1001 Accuracy: 0.7067 Loss: 1.19471180 time: 0.0020s\n",
      "Epoch: 2001 Accuracy: 0.7115 Loss: 1.19317508 time: 0.0030s\n",
      "Epoch: 3001 Accuracy: 0.7163 Loss: 1.18757558 time: 0.0020s\n",
      "Epoch: 4001 Accuracy: 0.7212 Loss: 1.18559003 time: 0.0020s\n",
      "Epoch: 5001 Accuracy: 0.7212 Loss: 1.18559003 time: 0.0030s\n",
      "Epoch: 6001 Accuracy: 0.7212 Loss: 1.18559003 time: 0.0020s\n",
      "Epoch: 7001 Accuracy: 0.7212 Loss: 1.18559003 time: 0.0020s\n",
      "Epoch: 8001 Accuracy: 0.7212 Loss: 1.18559003 time: 0.0030s\n",
      "Epoch: 9001 Accuracy: 0.7212 Loss: 1.18559003 time: 0.0030s\n",
      "Epoch: 10001 Accuracy: 0.7212 Loss: 1.18559003 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 23.4433s\n",
      "Epoch: 0001 Accuracy: 0.7212 Loss: 1.18559003 time: 0.0030s\n",
      "Epoch: 1001 Accuracy: 0.7212 Loss: 1.18495655 time: 0.0020s\n",
      "Epoch: 2001 Accuracy: 0.7212 Loss: 1.18414664 time: 0.0020s\n",
      "Epoch: 3001 Accuracy: 0.7212 Loss: 1.18325245 time: 0.0020s\n",
      "Epoch: 4001 Accuracy: 0.7308 Loss: 1.17548919 time: 0.0020s\n",
      "Epoch: 5001 Accuracy: 0.7308 Loss: 1.17548919 time: 0.0030s\n",
      "Epoch: 6001 Accuracy: 0.7308 Loss: 1.17548919 time: 0.0020s\n",
      "Epoch: 7001 Accuracy: 0.7308 Loss: 1.17548919 time: 0.0020s\n",
      "Epoch: 8001 Accuracy: 0.7308 Loss: 1.17548919 time: 0.0020s\n",
      "Epoch: 9001 Accuracy: 0.7308 Loss: 1.17548919 time: 0.0020s\n",
      "Epoch: 10001 Accuracy: 0.7308 Loss: 1.17548919 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 22.4260s\n",
      "Epoch: 0001 Accuracy: 0.7308 Loss: 1.17548919 time: 0.0030s\n",
      "Epoch: 1001 Accuracy: 0.7308 Loss: 1.17437744 time: 0.0030s\n",
      "Epoch: 2001 Accuracy: 0.7308 Loss: 1.17336679 time: 0.0020s\n",
      "Epoch: 3001 Accuracy: 0.7308 Loss: 1.17219639 time: 0.0020s\n",
      "Epoch: 4001 Accuracy: 0.7308 Loss: 1.17176902 time: 0.0020s\n",
      "Epoch: 5001 Accuracy: 0.7308 Loss: 1.17159188 time: 0.0020s\n",
      "Epoch: 6001 Accuracy: 0.7308 Loss: 1.17159188 time: 0.0030s\n",
      "Epoch: 7001 Accuracy: 0.7308 Loss: 1.17159188 time: 0.0020s\n",
      "Epoch: 8001 Accuracy: 0.7308 Loss: 1.17159188 time: 0.0020s\n",
      "Epoch: 9001 Accuracy: 0.7308 Loss: 1.17159188 time: 0.0030s\n",
      "Epoch: 10001 Accuracy: 0.7308 Loss: 1.17159188 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 21.8675s\n",
      "Epoch: 0001 Accuracy: 0.7308 Loss: 1.17159188 time: 0.0030s\n",
      "Epoch: 1001 Accuracy: 0.7308 Loss: 1.17126250 time: 0.0020s\n",
      "Epoch: 2001 Accuracy: 0.7308 Loss: 1.17071950 time: 0.0020s\n",
      "Epoch: 3001 Accuracy: 0.7356 Loss: 1.16955733 time: 0.0020s\n",
      "Epoch: 4001 Accuracy: 0.7356 Loss: 1.16912985 time: 0.0020s\n",
      "Epoch: 5001 Accuracy: 0.7356 Loss: 1.16912985 time: 0.0030s\n",
      "Epoch: 6001 Accuracy: 0.7356 Loss: 1.16912985 time: 0.0020s\n",
      "Epoch: 7001 Accuracy: 0.7356 Loss: 1.16912985 time: 0.0020s\n",
      "Epoch: 8001 Accuracy: 0.7356 Loss: 1.16912985 time: 0.0030s\n",
      "Epoch: 9001 Accuracy: 0.7356 Loss: 1.16912985 time: 0.0030s\n",
      "Epoch: 10001 Accuracy: 0.7356 Loss: 1.16912985 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 21.9952s\n",
      "Epoch: 0001 Accuracy: 0.7356 Loss: 1.16912985 time: 0.0020s\n",
      "Epoch: 1001 Accuracy: 0.7356 Loss: 1.16862118 time: 0.0020s\n",
      "Epoch: 2001 Accuracy: 0.7356 Loss: 1.16832089 time: 0.0020s\n",
      "Epoch: 3001 Accuracy: 0.7356 Loss: 1.16826427 time: 0.0020s\n",
      "Epoch: 4001 Accuracy: 0.7356 Loss: 1.16818011 time: 0.0020s\n",
      "Epoch: 5001 Accuracy: 0.7356 Loss: 1.16807389 time: 0.0030s\n",
      "Epoch: 6001 Accuracy: 0.7356 Loss: 1.16802669 time: 0.0030s\n",
      "Epoch: 7001 Accuracy: 0.7356 Loss: 1.16802669 time: 0.0030s\n",
      "Epoch: 8001 Accuracy: 0.7356 Loss: 1.16802669 time: 0.0030s\n",
      "Epoch: 9001 Accuracy: 0.7356 Loss: 1.16802669 time: 0.0020s\n",
      "Epoch: 10001 Accuracy: 0.7356 Loss: 1.16802669 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 21.6517s\n",
      "Epoch: 0001 Accuracy: 0.7356 Loss: 1.16802669 time: 0.0020s\n",
      "Epoch: 1001 Accuracy: 0.7356 Loss: 1.16801178 time: 0.0020s\n",
      "Epoch: 2001 Accuracy: 0.7356 Loss: 1.16797900 time: 0.0020s\n",
      "Epoch: 3001 Accuracy: 0.7356 Loss: 1.16791987 time: 0.0020s\n",
      "Epoch: 4001 Accuracy: 0.7356 Loss: 1.16781151 time: 0.0020s\n",
      "Epoch: 5001 Accuracy: 0.7356 Loss: 1.16757524 time: 0.0020s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6001 Accuracy: 0.7356 Loss: 1.16750956 time: 0.0020s\n",
      "Epoch: 7001 Accuracy: 0.7356 Loss: 1.16750956 time: 0.0020s\n",
      "Epoch: 8001 Accuracy: 0.7356 Loss: 1.16750956 time: 0.0020s\n",
      "Epoch: 9001 Accuracy: 0.7356 Loss: 1.16750956 time: 0.0020s\n",
      "Epoch: 10001 Accuracy: 0.7356 Loss: 1.16750956 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 21.9583s\n",
      "Epoch: 0001 Accuracy: 0.7356 Loss: 1.16750956 time: 0.0030s\n",
      "Epoch: 1001 Accuracy: 0.7356 Loss: 1.16748667 time: 0.0020s\n",
      "Epoch: 2001 Accuracy: 0.7356 Loss: 1.16741848 time: 0.0020s\n",
      "Epoch: 3001 Accuracy: 0.7356 Loss: 1.16724920 time: 0.0020s\n",
      "Epoch: 4001 Accuracy: 0.7356 Loss: 1.16692913 time: 0.0020s\n",
      "Epoch: 5001 Accuracy: 0.7356 Loss: 1.16653430 time: 0.0030s\n",
      "Epoch: 6001 Accuracy: 0.7356 Loss: 1.16653430 time: 0.0030s\n",
      "Epoch: 7001 Accuracy: 0.7356 Loss: 1.16653430 time: 0.0020s\n",
      "Epoch: 8001 Accuracy: 0.7356 Loss: 1.16653430 time: 0.0020s\n",
      "Epoch: 9001 Accuracy: 0.7356 Loss: 1.16653430 time: 0.0020s\n",
      "Epoch: 10001 Accuracy: 0.7356 Loss: 1.16653430 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 22.0639s\n",
      "Epoch: 0001 Accuracy: 0.7356 Loss: 1.16653430 time: 0.0030s\n",
      "Epoch: 1001 Accuracy: 0.7356 Loss: 1.16626871 time: 0.0030s\n",
      "Epoch: 2001 Accuracy: 0.7356 Loss: 1.16585374 time: 0.0020s\n",
      "Epoch: 3001 Accuracy: 0.7404 Loss: 1.16499758 time: 0.0020s\n",
      "Epoch: 4001 Accuracy: 0.7404 Loss: 1.16436088 time: 0.0030s\n",
      "Epoch: 5001 Accuracy: 0.7404 Loss: 1.16436088 time: 0.0020s\n",
      "Epoch: 6001 Accuracy: 0.7404 Loss: 1.16436088 time: 0.0030s\n",
      "Epoch: 7001 Accuracy: 0.7404 Loss: 1.16436088 time: 0.0030s\n",
      "Epoch: 8001 Accuracy: 0.7404 Loss: 1.16436088 time: 0.0020s\n",
      "Epoch: 9001 Accuracy: 0.7404 Loss: 1.16436088 time: 0.0030s\n",
      "Epoch: 10001 Accuracy: 0.7404 Loss: 1.16436088 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 21.8067s\n",
      "Epoch: 0001 Accuracy: 0.7404 Loss: 1.16436088 time: 0.0030s\n",
      "Epoch: 1001 Accuracy: 0.7404 Loss: 1.16392028 time: 0.0030s\n",
      "Epoch: 2001 Accuracy: 0.7404 Loss: 1.16298211 time: 0.0030s\n",
      "Epoch: 3001 Accuracy: 0.7452 Loss: 1.15799415 time: 0.0030s\n",
      "Epoch: 4001 Accuracy: 0.7452 Loss: 1.15783799 time: 0.0030s\n",
      "Epoch: 5001 Accuracy: 0.7452 Loss: 1.15783799 time: 0.0030s\n",
      "Epoch: 6001 Accuracy: 0.7452 Loss: 1.15783799 time: 0.0020s\n",
      "Epoch: 7001 Accuracy: 0.7452 Loss: 1.15783799 time: 0.0020s\n",
      "Epoch: 8001 Accuracy: 0.7452 Loss: 1.15783799 time: 0.0020s\n",
      "Epoch: 9001 Accuracy: 0.7452 Loss: 1.15783799 time: 0.0020s\n",
      "Epoch: 10001 Accuracy: 0.7452 Loss: 1.15783799 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 22.2451s\n",
      "Epoch: 0001 Accuracy: 0.7452 Loss: 1.15783799 time: 0.0030s\n",
      "Epoch: 1001 Accuracy: 0.7452 Loss: 1.15781856 time: 0.0020s\n",
      "Epoch: 2001 Accuracy: 0.7452 Loss: 1.15777755 time: 0.0020s\n",
      "Epoch: 3001 Accuracy: 0.7452 Loss: 1.15772009 time: 0.0030s\n",
      "Epoch: 4001 Accuracy: 0.7452 Loss: 1.15765882 time: 0.0020s\n",
      "Epoch: 5001 Accuracy: 0.7452 Loss: 1.15758634 time: 0.0020s\n",
      "Epoch: 6001 Accuracy: 0.7452 Loss: 1.15753949 time: 0.0020s\n",
      "Epoch: 7001 Accuracy: 0.7452 Loss: 1.15748036 time: 0.0020s\n",
      "Epoch: 8001 Accuracy: 0.7452 Loss: 1.15736234 time: 0.0189s\n",
      "Epoch: 9001 Accuracy: 0.7452 Loss: 1.15627313 time: 0.0030s\n",
      "Epoch: 10001 Accuracy: 0.7500 Loss: 1.15401495 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 23.7774s\n",
      "Epoch: 0001 Accuracy: 0.7500 Loss: 1.15401495 time: 0.0030s\n",
      "Epoch: 1001 Accuracy: 0.7500 Loss: 1.15399754 time: 0.0020s\n",
      "Epoch: 2001 Accuracy: 0.7500 Loss: 1.15398514 time: 0.0020s\n",
      "Epoch: 3001 Accuracy: 0.7500 Loss: 1.15396762 time: 0.0020s\n",
      "Epoch: 4001 Accuracy: 0.7500 Loss: 1.15394449 time: 0.0020s\n",
      "Epoch: 5001 Accuracy: 0.7500 Loss: 1.15391326 time: 0.0030s\n",
      "Epoch: 6001 Accuracy: 0.7500 Loss: 1.15386772 time: 0.0020s\n",
      "Epoch: 7001 Accuracy: 0.7500 Loss: 1.15379357 time: 0.0020s\n",
      "Epoch: 8001 Accuracy: 0.7500 Loss: 1.15364659 time: 0.0020s\n",
      "Epoch: 9001 Accuracy: 0.7548 Loss: 1.15029287 time: 0.0020s\n",
      "Epoch: 10001 Accuracy: 0.7548 Loss: 1.15029287 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 21.9932s\n",
      "Epoch: 0001 Accuracy: 0.7548 Loss: 1.15029287 time: 0.0030s\n",
      "Epoch: 1001 Accuracy: 0.7548 Loss: 1.14997613 time: 0.0020s\n",
      "Epoch: 2001 Accuracy: 0.7548 Loss: 1.14953220 time: 0.0020s\n",
      "Epoch: 3001 Accuracy: 0.7548 Loss: 1.14952934 time: 0.0030s\n",
      "Epoch: 4001 Accuracy: 0.7548 Loss: 1.14952326 time: 0.0030s\n",
      "Epoch: 5001 Accuracy: 0.7548 Loss: 1.14951396 time: 0.0030s\n",
      "Epoch: 6001 Accuracy: 0.7548 Loss: 1.14950073 time: 0.0020s\n",
      "Epoch: 7001 Accuracy: 0.7548 Loss: 1.14948189 time: 0.0020s\n",
      "Epoch: 8001 Accuracy: 0.7548 Loss: 1.14945304 time: 0.0020s\n",
      "Epoch: 9001 Accuracy: 0.7548 Loss: 1.14941299 time: 0.0020s\n",
      "Epoch: 10001 Accuracy: 0.7548 Loss: 1.14940321 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 22.1215s\n",
      "Epoch: 0001 Accuracy: 0.7548 Loss: 1.14940321 time: 0.0030s\n",
      "Epoch: 1001 Accuracy: 0.7548 Loss: 1.14940321 time: 0.0020s\n",
      "Epoch: 2001 Accuracy: 0.7548 Loss: 1.14940321 time: 0.0020s\n",
      "Epoch: 3001 Accuracy: 0.7548 Loss: 1.14940321 time: 0.0020s\n",
      "Epoch: 4001 Accuracy: 0.7548 Loss: 1.14940321 time: 0.0020s\n",
      "Epoch: 5001 Accuracy: 0.7548 Loss: 1.14940321 time: 0.0030s\n",
      "Epoch: 6001 Accuracy: 0.7548 Loss: 1.14940321 time: 0.0040s\n",
      "Epoch: 7001 Accuracy: 0.7548 Loss: 1.14940321 time: 0.0030s\n",
      "Epoch: 8001 Accuracy: 0.7548 Loss: 1.14940321 time: 0.0040s\n",
      "Epoch: 9001 Accuracy: 0.7548 Loss: 1.14940321 time: 0.0030s\n",
      "Epoch: 10001 Accuracy: 0.7548 Loss: 1.14940321 time: 0.0040s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 28.1736s\n"
     ]
    }
   ],
   "source": [
    "mask_percentage = [1.]\n",
    "\n",
    "for m in mask_percentage:\n",
    "    \n",
    "    #features = np.expand_dims(feature, axis=0)\n",
    "    #print(features.shape)\n",
    "    \n",
    "    # Masking\n",
    "    number_of_rows = features[0].shape[0]\n",
    "    random_indices = np.random.choice(number_of_rows, size=int(m*number_of_rows), replace=False)\n",
    "    \n",
    "    # exclude low activity areas from masking\n",
    "    zip_sum = data.groupby(by='origin', as_index=False).sum()\n",
    "    low_act = zip_sum[zip_sum.weight < 3000].index\n",
    "    \n",
    "    random_indices = np.setdiff1d(random_indices, low_act)\n",
    "    random_rows = features[0][random_indices, :]\n",
    "    features[0][random_indices, :] = np.tile(np.array([[0.2]]),random_rows.shape)\n",
    "    \n",
    "    \n",
    "    print(\"\\nMasked {}% of nodes\\n\".format(int(m*100)))\n",
    "    prev_loss, op = train(adj,features,labels, random_indices, True)\n",
    "    #print(op)\n",
    "    loss, op = train(adj,op.cpu().detach().numpy(),labels, random_indices)\n",
    "    while loss < prev_loss :\n",
    "        prev_loss = loss\n",
    "        loss, op = train(adj,op.cpu().detach().numpy(),labels, random_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
