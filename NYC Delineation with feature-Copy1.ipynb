{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## City district delineation using Graph Neural Networks\n",
    "\n",
    "### Graph Neural Networks\n",
    "\n",
    "\n",
    "Graph Neural Networks (GNNs) are a class of deep learning methods designed to perform inference on data described by graphs. GNNs are neural networks that can be directly applied to graphs, and provide an easy way to do node-level, edge-level, and graph-level prediction tasks. \n",
    "\n",
    "Anything that is composed of linked entities can be represented as a graph. Graphs are excellent tools to visualize relations between people, objects, and concepts. With graphs becoming more pervasive and richer with information, and artificial neural networks becoming more popular and capable, GNNs have become a powerful tool for many important applications.\n",
    "\n",
    "<img src='GNN.png' width=\"600\" height=\"600\">\n",
    "\n",
    "Graph neural networks can be created like any other neural network, using fully connected layers, convolutional layers, pooling layers, etc. The type and number of layers depend on the type and complexity of the graph data and the desired output.\n",
    "\n",
    "The GNN receives the formatted graph data as input and produces a vector of numerical values that represent relevant information about nodes and their relations. This vector representation is called “graph embedding.”\n",
    "\n",
    "One very popular GNN architecture is the graph convolutional neural network (GCN), which uses convolution layers to create graph embeddings. (Kipf, T.N. and Welling, M., 2016. Semi-supervised classification with graph convolutional networks. https://arxiv.org/pdf/1609.02907.pdf)\n",
    "\n",
    "In the recent years, a lot of work has been done on the problem of generalizing neural networks to work on arbitrarily structured graphs - Bruna, J., Zaremba, W., Szlam, A. and LeCun, Y., 2013. Spectral networks and locally connected networks on graphs. https://arxiv.org/pdf/1312.6203.pdf%20http://arxiv.org/abs/1312.6203.pdf,  Henaff, M., Bruna, J. and LeCun, Y., 2015. Deep convolutional networks on graph-structured data. https://arxiv.org/abs/1506.05163 etc.\n",
    "\n",
    " \n",
    "Few applications for graph neural networks:\n",
    "\n",
    "- Node classification: One of the powerful applications of GNNs is adding new information to nodes or filling gaps where information is missing. For example, say you are running a social network and you have spotted a few bot accounts. Now you want to find out if there are other bot accounts in your network. You can train a GNN to classify other users in the social network as “bot” or “not bot” based on how close their graph embeddings are to those of the known bots.\n",
    "\n",
    "- Edge prediction: Another way to put GNNs to use is to find new edges that can add value to the graph. Going back to our social network, a GNN can find users (nodes) who are close to you in embedding space but who aren’t your friends yet (i.e., there isn’t an edge connecting you to each other). These users can then be introduced to you as friend suggestions.\n",
    "\n",
    "- Clustering: GNNs can glean new structural information from graphs. For example, in a social network where everyone is in one way or another related to others (through friends, or friends of friends, etc.), the GNN can find nodes that form clusters in the embedding space.\n",
    "\n",
    "A comprehensive tutorial on GNNs by Stanford is available on Youtube: https://www.youtube.com/watch?v=JAB_plj2rbA&list=PLoROMvodv4rPLKxIpqhjhPgdQy7imNkDn\n",
    "\n",
    "### GNN for city delineation\n",
    "\n",
    "Here, we demonstrate an application for GNN for city borough delineation. The relationships among various entities such as interaction among people, intra-city mobility, social media interactions can be interpreted in terms of graphs with many features associated with nodes, edges. \n",
    "\n",
    "We will use the LEHD mobility network among zip codes in NYC and use it to learn the corresponding borough of zip codes (nodes) in the city. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data overview\n",
    "\n",
    "The LEHD mobility matrix contains the commute numbers between the home and work zip codes of the population..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin</th>\n",
       "      <th>destination</th>\n",
       "      <th>weight</th>\n",
       "      <th>initialFeat</th>\n",
       "      <th>true_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11436</td>\n",
       "      <td>10009</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11436</td>\n",
       "      <td>10011</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11436</td>\n",
       "      <td>10013</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11436</td>\n",
       "      <td>10019</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11436</td>\n",
       "      <td>10021</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   origin  destination  weight  initialFeat  true_label\n",
       "0   11436        10009       1          4.0           4\n",
       "1   11436        10011       1          4.0           4\n",
       "2   11436        10013       1          4.0           4\n",
       "3   11436        10019       1          4.0           4\n",
       "4   11436        10021       1          4.0           4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/zips_merged.csv', delimiter=',')\n",
    "data = data.rename(columns={'total': 'weight', 'w_zip':'origin', 'h_zip':'destination'})\n",
    "data = data[data.destination.isin(data.origin.unique())]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the population feature into the dataset\n",
    "\n",
    "populationByAge = pd.read_csv('data/zicode_populationByAge.csv', delimiter=',')\n",
    "populationByAge = populationByAge.iloc[:,0:2]\n",
    "populationByAge.rename(columns={'ZIPCODE':'destination', 'Estimate!!Total!!Total population' : 'population' }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the house price feature into the dataset\n",
    "\n",
    "housePrice = pd.read_csv('data/zipcode_housePrice.csv', delimiter=',')\n",
    "weights = [5000,12500,17500,22500,27500,32500,37500,45000,55000,65000,75000,85000\n",
    "                    ,95000,112500,137500,162500,187500,225000,275000,350000,450000,625000,875000\n",
    "                        ,1250000,1750000,2000000]\n",
    "for i in range(len(weights)):\n",
    "    housePrice.iloc[i,2:] = housePrice.iloc[i,2:]*weights[i]\n",
    "housePrice.iloc[:,1] [housePrice.iloc[:,1] == 0] = 1\n",
    "\n",
    "tmp = (housePrice.iloc[:,2:] != 0 ).sum(axis=1)\n",
    "tmp[tmp == 0] = 1\n",
    "housePrice = pd.concat([housePrice.iloc[:,0],housePrice.iloc[:,2:].sum(axis=1) / tmp ], axis = 1 )\n",
    "housePrice.rename(columns={'ZIPCODE':'destination', 0: 'house_price'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the area size feature into the dataset\n",
    "\n",
    "area = pd.read_csv('data/zips_area.csv', delimiter=',')\n",
    "area = area.iloc[:,:2]\n",
    "area.rename(columns={'ZIPCODE':'destination', 'AREA' : 'area'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the income level feature into the dataset\n",
    "\n",
    "income = pd.read_csv('data/zipcode_income.csv', delimiter=',')\n",
    "income = income.iloc[:,:2]\n",
    "income[income.isna()] = 0\n",
    "income.rename(columns={'ZIPCODE':'destination', 'median_familyIncome(USD)' : 'income'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the population jobs feature into the dataset\n",
    "\n",
    "populationJobs = pd.read_csv('data/zipcode_population_Jobs.csv', delimiter=',')\n",
    "populationJobs = populationJobs.iloc[:,:2]\n",
    "populationJobs.rename(columns={'ZIPCODE':'destination', 'totalJobs' : 'jobs'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(populationByAge)\n",
    "data = data.merge(housePrice)\n",
    "data = data.merge(area)\n",
    "data = data.merge(income)\n",
    "data = data.merge(populationJobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the features\n",
    "\n",
    "data.iloc[:,5:]=(data.iloc[:,5:]-data.iloc[:,5:].min())/(data.iloc[:,5:].max()-data.iloc[:,5:].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin</th>\n",
       "      <th>destination</th>\n",
       "      <th>weight</th>\n",
       "      <th>initialFeat</th>\n",
       "      <th>true_label</th>\n",
       "      <th>population</th>\n",
       "      <th>house_price</th>\n",
       "      <th>area</th>\n",
       "      <th>income</th>\n",
       "      <th>jobs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11436</td>\n",
       "      <td>10009</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.300165</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.032183</td>\n",
       "      <td>0.243977</td>\n",
       "      <td>0.042630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11213</td>\n",
       "      <td>10009</td>\n",
       "      <td>14</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.300165</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.032183</td>\n",
       "      <td>0.243977</td>\n",
       "      <td>0.042630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11212</td>\n",
       "      <td>10009</td>\n",
       "      <td>27</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.300165</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.032183</td>\n",
       "      <td>0.243977</td>\n",
       "      <td>0.042630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11225</td>\n",
       "      <td>10009</td>\n",
       "      <td>26</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.300165</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.032183</td>\n",
       "      <td>0.243977</td>\n",
       "      <td>0.042630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11218</td>\n",
       "      <td>10009</td>\n",
       "      <td>60</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.300165</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.032183</td>\n",
       "      <td>0.243977</td>\n",
       "      <td>0.042630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36407</th>\n",
       "      <td>11211</td>\n",
       "      <td>11371</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36408</th>\n",
       "      <td>11373</td>\n",
       "      <td>11371</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36409</th>\n",
       "      <td>10168</td>\n",
       "      <td>11371</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36410</th>\n",
       "      <td>10278</td>\n",
       "      <td>11371</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36411</th>\n",
       "      <td>10036</td>\n",
       "      <td>11371</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36412 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       origin  destination  weight  initialFeat  true_label  population  \\\n",
       "0       11436        10009       1          4.0           4    0.300165   \n",
       "1       11213        10009      14          3.0           3    0.300165   \n",
       "2       11212        10009      27          3.0           3    0.300165   \n",
       "3       11225        10009      26          3.0           3    0.300165   \n",
       "4       11218        10009      60          3.0           3    0.300165   \n",
       "...       ...          ...     ...          ...         ...         ...   \n",
       "36407   11211        11371       7          1.0           3    0.000000   \n",
       "36408   11373        11371       3          4.0           4    0.000000   \n",
       "36409   10168        11371       1          1.0           1    0.000000   \n",
       "36410   10278        11371       1          1.0           1    0.000000   \n",
       "36411   10036        11371       5          1.0           1    0.000000   \n",
       "\n",
       "       house_price      area    income      jobs  \n",
       "0         0.005332  0.032183  0.243977  0.042630  \n",
       "1         0.005332  0.032183  0.243977  0.042630  \n",
       "2         0.005332  0.032183  0.243977  0.042630  \n",
       "3         0.005332  0.032183  0.243977  0.042630  \n",
       "4         0.005332  0.032183  0.243977  0.042630  \n",
       "...            ...       ...       ...       ...  \n",
       "36407     0.000000  0.063146  0.000000  0.050874  \n",
       "36408     0.000000  0.063146  0.000000  0.050874  \n",
       "36409     0.000000  0.063146  0.000000  0.050874  \n",
       "36410     0.000000  0.063146  0.000000  0.050874  \n",
       "36411     0.000000  0.063146  0.000000  0.050874  \n",
       "\n",
       "[36412 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set initial model config\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "weight_decay = 10e-4\n",
    "epochs = 10001\n",
    "seed = 165\n",
    "hidden = 10\n",
    "lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a symmetric normalization for the propogating the layer, i.e. $$D^{−1/2}AD^{−1/2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(adj):\n",
    "\n",
    "    adj = torch.FloatTensor(adj)\n",
    "    adj_id = torch.FloatTensor(torch.eye(adj.shape[1]))\n",
    "    adj_id = adj_id.reshape((1, adj.shape[1], adj.shape[1]))\n",
    "    adj_id = adj_id.repeat(adj.shape[0], 1, 1)\n",
    "    adj = adj + adj_id\n",
    "    rowsum = torch.FloatTensor(adj.sum(2))\n",
    "    degree_mat_inv_sqrt = torch.diag_embed(torch.float_power(rowsum,-0.5), dim1=-2, dim2=-1).float()\n",
    "    adj_norm = torch.bmm(torch.transpose(torch.bmm(adj,degree_mat_inv_sqrt),1,2),degree_mat_inv_sqrt)\n",
    "\n",
    "    return adj_norm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The activation function for the GNN is the double ReLU which is linear between between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doublerelu(x):\n",
    "    return torch.clamp(x, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Layer propogation rule of the GNN is : $$ H^{(l+1)} = f(H^{(l)}, A) = \\sigma ( H^{(l)}W_1^{(l)} + \\hat{D}^{-1/2}\\hat{A}\\hat{D}^{-1/2}H^{(l)}W_2^{(l)}) $$\n",
    "\n",
    "where H is the l'th neural network layer, A is the adjaceny matrix, D is the diagonal node degree matrix, W1 , W2 are learnable weight matrices initialised as W1 = 1, W2 = 0  and sigma is the activation function doublerelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN1Layer(Module):\n",
    "\n",
    "    def __init__(self, batch_size, in_features, out_features, first):\n",
    "        super(GNN1Layer, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # Initialse W1 = 1, W2 = 0 as pytorch learnable weights (parameters) that have require_grad = True which is\n",
    "        # required for calculating gradients while backpropogating using gradient descent\n",
    "        weight1_eye = torch.FloatTensor(torch.eye(in_features, out_features))\n",
    "        weight1_eye = weight1_eye.reshape((1, in_features, out_features))\n",
    "        weight1_eye = weight1_eye.repeat(batch_size, 1, 1)\n",
    "        self.weight1 = Parameter(weight1_eye)\n",
    "        if not first:\n",
    "            self.weight2 = Parameter(torch.zeros(batch_size, in_features, out_features))\n",
    "        else:\n",
    "            self.weight2 = Parameter(torch.empty(batch_size, in_features, out_features))\n",
    "            nn.init.kaiming_normal_(self.weight2, mode='fan_out')\n",
    "\n",
    "    def forward(self, input, adj):\n",
    "        # first term H*W1\n",
    "        v1 = torch.bmm(input, self.weight1)\n",
    "        # second term adj_norm*H*W2\n",
    "        v2 = torch.bmm(torch.bmm(adj, input), self.weight2)\n",
    "        # adding the two terms\n",
    "        output = v1 + v2\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN1(nn.Module):\n",
    "\n",
    "    def __init__(self, batch_size, nfeat, ndim, hidden, first):\n",
    "        super(GNN1, self).__init__()\n",
    "\n",
    "        self.gc1 = GNN1Layer(batch_size, nfeat, ndim, first)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        \n",
    "        # Applying activation function sigma (doublerelu) on the layer propogation\n",
    "        x = doublerelu(self.gc1(x, adj))\n",
    "        x = x/x.sum(axis=2).unsqueeze(2) #normalize st sum = 1\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(adj,features,labels,val_adj,val_features,val_labels,first=False):\n",
    "    \n",
    "    # calculate symmetric normalisation for layer propogation\n",
    "    adj_norm = normalize(adj)\n",
    "    \n",
    "    labels = labels - 1\n",
    "    \n",
    "    # Convert from numpy to torch tensors\n",
    "    adj = torch.FloatTensor(adj)\n",
    "    adj_norm = torch.FloatTensor(adj_norm)\n",
    "    features = torch.FloatTensor(features)\n",
    "    labels = torch.FloatTensor(labels)\n",
    "    \n",
    "    # initialise the mode\n",
    "    model = GNN1(batch_size=adj.shape[0],\n",
    "                nfeat=features.shape[-1],\n",
    "                ndim=nb_label,\n",
    "                hidden=hidden,\n",
    "                first=first)\n",
    "    \n",
    "    # Validation tensors\n",
    "    val_adj_norm = normalize(val_adj)\n",
    "    val_labels = val_labels - 1\n",
    "    \n",
    "    val_adj = torch.FloatTensor(val_adj)\n",
    "    val_adj_norm = torch.FloatTensor(val_adj_norm)\n",
    "    val_features = torch.FloatTensor(val_features)\n",
    "    val_labels = torch.FloatTensor(val_labels)\n",
    "    \n",
    "    # Transfer the weights to GPU for training\n",
    "    if cuda:\n",
    "        model.cuda()\n",
    "        features = features.cuda()\n",
    "        adj = adj.cuda()\n",
    "        adj_norm = adj_norm.cuda()\n",
    "        labels = labels.cuda()\n",
    "        \n",
    "        val_features = val_features.cuda()\n",
    "        val_adj = val_adj.cuda()\n",
    "        val_adj_norm = val_adj_norm.cuda()\n",
    "        val_labels = val_labels.cuda()\n",
    "        \n",
    "        \n",
    "    \n",
    "    # Train model\n",
    "    t_total = time.time()\n",
    "\n",
    "    # Using adam optimizers for backpropogation\n",
    "    optimizer = optim.Adam(model.parameters(),\n",
    "                           lr=lr, weight_decay=weight_decay)\n",
    "    \n",
    "    # loss function criteria is cross entropy loss\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Train for the no of epochs\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        t = time.time()\n",
    "        model.train()\n",
    "        \n",
    "        # Pytorch accumulates gradient after every operation on tensors (defined by the model architecture)\n",
    "        # with require_grad = True. With each new epoch, we need to reset this gradient to 0 to calculate gradient\n",
    "        # for this epoch.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # get the output from forward propogation of our model\n",
    "        output = model(features, adj_norm)\n",
    "        # validation output\n",
    "        val_output = model(val_features, val_adj_norm)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        accuracy = torch.sum(torch.argmax(output,axis=2)==labels.reshape(1,-1))/labels.shape[0]\n",
    "        # Validation accuracy\n",
    "        val_accuracy = torch.sum(torch.argmax(val_output,axis=2)==val_labels.reshape(1,-1))/val_labels.shape[0]\n",
    "        #if epoch%100 == 0:\n",
    "            #print(torch.argmax(val_output,axis=2))\n",
    "            #print(torch.argmax(output,axis=2))\n",
    "            #rint(val_labels.reshape(1,-1))\n",
    "            #rint(labels.reshape(1,-1))\n",
    "        # Calculate the loss between our models training output and true label\n",
    "        loss = criterion(output[0],labels.reshape(-1).long())\n",
    "        \n",
    "        # Calculate the gradients \n",
    "        loss.backward()\n",
    "\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print summary of training \n",
    "        if epoch == 0:\n",
    "            best_loss = loss\n",
    "            best_output = output\n",
    "            best_acc = accuracy\n",
    "            best_val_acc = val_accuracy\n",
    "        else:\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "                best_output = output\n",
    "                best_acc = accuracy\n",
    "                best_val_acc = val_accuracy\n",
    "\n",
    "        if epoch % 1000 == 0:\n",
    "            print('Epoch: {:04d}'.format(epoch + 1),\n",
    "                  'Accuracy: {:.4f}'.format(best_acc.item()),\n",
    "                  'Validation Accuracy: {:.4f}'.format(best_val_acc.item()),\n",
    "                  'Loss: {:.8f}'.format(best_loss.item()),\n",
    "                  'time: {:.4f}s'.format(time.time() - t))\n",
    "            \n",
    "    print(\"Optimization Finished!\")\n",
    "    print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
    "    \n",
    "    return best_loss,best_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svdApprox(adj, dim, relu=False):\n",
    "    adj = torch.FloatTensor(adj[0])\n",
    "    U, S, Vh = torch.linalg.svd(adj)\n",
    "    mu = torch.matmul(torch.matmul(U[:, :dim], torch.diag(S[:dim])), Vh[:dim, :])\n",
    "\n",
    "    embedx = torch.matmul(U[:, :dim], torch.diag(torch.pow(S[:dim], 0.5)))\n",
    "    embedy = torch.transpose(torch.matmul(torch.diag(torch.pow(S[:dim], 0.5)), Vh[:dim, :]), 0, 1)\n",
    "\n",
    "    return embedx, embedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for loading data, returns adjacency matrix, initial feature assignments and true labels\n",
    "\n",
    "def load_data():\n",
    "\n",
    "    G = nx.from_pandas_edgelist(data, 'origin', 'destination', 'weight',create_using=nx.DiGraph())\n",
    "    adj_list = np.array([nx.adjacency_matrix(G).todense()], dtype=float)\n",
    "    \n",
    "    init_feat1 = np.array(data.groupby('origin')['population'].agg(['unique']))\n",
    "    init_feat1 = np.array(list(map(lambda x: x[0][0], init_feat1))).reshape(-1, 1)\n",
    "    init_feat2 = np.array(data.groupby('origin')['house_price'].agg(['unique']))\n",
    "    init_feat2 = np.array(list(map(lambda x: x[0][0], init_feat2))).reshape(-1, 1)\n",
    "    init_feat3 = np.array(data.groupby('origin')['area'].agg(['unique']))\n",
    "    init_feat3 = np.array(list(map(lambda x: x[0][0], init_feat3))).reshape(-1, 1)\n",
    "    init_feat4 = np.array(data.groupby('origin')['income'].agg(['unique']))\n",
    "    init_feat4 = np.array(list(map(lambda x: x[0][0], init_feat4))).reshape(-1, 1)\n",
    "    init_feat5 = np.array(data.groupby('origin')['jobs'].agg(['unique']))\n",
    "    init_feat5 = np.array(list(map(lambda x: x[0][0], init_feat5))).reshape(-1, 1)\n",
    "    \n",
    "    init_feat = np.concatenate([init_feat1,init_feat2,init_feat3,init_feat4,init_feat5],axis=1)\n",
    "    \n",
    "    true_label = np.array(data.groupby('origin')['true_label'].agg(['unique']))\n",
    "    \n",
    "    true_label = np.array(list(map(lambda x: x[0][0], true_label))).reshape(-1, 1)\n",
    "    return adj_list,init_feat,true_label\n",
    "\n",
    "adj,feature,labels = load_data()\n",
    "\n",
    "features = np.expand_dims(feature, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_feat = np.array(data.groupby('origin')['initialFeat'].agg(['unique']))\n",
    "init_feat = np.array(list(map(lambda x: x[0][0], init_feat))).reshape(-1, 1)\n",
    "init_feat = init_feat - 1\n",
    "nb_label = int(max(init_feat)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and validation for out of sample evaluation\n",
    "\n",
    "train_per = 0.8\n",
    "val_per = 1-train_per\n",
    "number_of_rows = features.shape[1]\n",
    "train_indices = int(0.8*number_of_rows)\n",
    "\n",
    "train_adj = adj[:,:train_indices,:train_indices]\n",
    "train_features = features[:,:train_indices,:]\n",
    "train_labels = labels[:train_indices,:]\n",
    "\n",
    "val_adj = adj[:,train_indices:,train_indices:]\n",
    "val_features = features[:,train_indices:,:]\n",
    "val_labels = labels[train_indices:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 Accuracy: 0.2410 Validation Accuracy: 0.0000 Loss: 1.62984526 time: 0.3999s\n",
      "Epoch: 1001 Accuracy: 0.3072 Validation Accuracy: 0.0000 Loss: 1.58808255 time: 0.0019s\n",
      "Epoch: 2001 Accuracy: 0.3614 Validation Accuracy: 0.0000 Loss: 1.49033451 time: 0.0020s\n",
      "Epoch: 3001 Accuracy: 0.3976 Validation Accuracy: 0.0000 Loss: 1.47629273 time: 0.0019s\n",
      "Epoch: 4001 Accuracy: 0.4036 Validation Accuracy: 0.0000 Loss: 1.47074306 time: 0.0010s\n",
      "Epoch: 5001 Accuracy: 0.4157 Validation Accuracy: 0.0000 Loss: 1.46660948 time: 0.0010s\n",
      "Epoch: 6001 Accuracy: 0.4217 Validation Accuracy: 0.0000 Loss: 1.46226573 time: 0.0010s\n",
      "Epoch: 7001 Accuracy: 0.4217 Validation Accuracy: 0.0000 Loss: 1.45665860 time: 0.0018s\n",
      "Epoch: 8001 Accuracy: 0.4277 Validation Accuracy: 0.0000 Loss: 1.44594073 time: 0.0010s\n",
      "Epoch: 9001 Accuracy: 0.4458 Validation Accuracy: 0.0000 Loss: 1.43270850 time: 0.0010s\n",
      "Epoch: 10001 Accuracy: 0.4699 Validation Accuracy: 0.0000 Loss: 1.40995753 time: 0.0010s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 12.9125s\n",
      "Epoch: 0001 Accuracy: 0.4699 Validation Accuracy: 0.0000 Loss: 1.40995753 time: 0.0020s\n",
      "Epoch: 1001 Accuracy: 0.4759 Validation Accuracy: 0.9762 Loss: 1.39423203 time: 0.0010s\n",
      "Epoch: 2001 Accuracy: 0.4819 Validation Accuracy: 1.0000 Loss: 1.37454581 time: 0.0010s\n",
      "Epoch: 3001 Accuracy: 0.4880 Validation Accuracy: 1.0000 Loss: 1.36118972 time: 0.0010s\n",
      "Epoch: 4001 Accuracy: 0.4880 Validation Accuracy: 1.0000 Loss: 1.36118972 time: 0.0010s\n",
      "Epoch: 5001 Accuracy: 0.4880 Validation Accuracy: 1.0000 Loss: 1.36118972 time: 0.0010s\n",
      "Epoch: 6001 Accuracy: 0.4880 Validation Accuracy: 1.0000 Loss: 1.36118972 time: 0.0010s\n",
      "Epoch: 7001 Accuracy: 0.4880 Validation Accuracy: 1.0000 Loss: 1.36118972 time: 0.0020s\n",
      "Epoch: 8001 Accuracy: 0.4880 Validation Accuracy: 1.0000 Loss: 1.36118972 time: 0.0010s\n",
      "Epoch: 9001 Accuracy: 0.4880 Validation Accuracy: 1.0000 Loss: 1.36118972 time: 0.0020s\n",
      "Epoch: 10001 Accuracy: 0.4880 Validation Accuracy: 1.0000 Loss: 1.36118972 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 12.5038s\n",
      "Epoch: 0001 Accuracy: 0.4880 Validation Accuracy: 0.0000 Loss: 1.36118972 time: 0.0010s\n",
      "Epoch: 1001 Accuracy: 0.5301 Validation Accuracy: 0.3571 Loss: 1.34507835 time: 0.0020s\n",
      "Epoch: 2001 Accuracy: 0.5964 Validation Accuracy: 0.0000 Loss: 1.32446575 time: 0.0013s\n",
      "Epoch: 3001 Accuracy: 0.6024 Validation Accuracy: 0.0238 Loss: 1.30584180 time: 0.0010s\n",
      "Epoch: 4001 Accuracy: 0.6024 Validation Accuracy: 0.0238 Loss: 1.30584180 time: 0.0010s\n",
      "Epoch: 5001 Accuracy: 0.6024 Validation Accuracy: 0.0238 Loss: 1.30584180 time: 0.0020s\n",
      "Epoch: 6001 Accuracy: 0.6024 Validation Accuracy: 0.0238 Loss: 1.30584180 time: 0.0020s\n",
      "Epoch: 7001 Accuracy: 0.6024 Validation Accuracy: 0.0238 Loss: 1.30584180 time: 0.0010s\n",
      "Epoch: 8001 Accuracy: 0.6024 Validation Accuracy: 0.0238 Loss: 1.30584180 time: 0.0010s\n",
      "Epoch: 9001 Accuracy: 0.6024 Validation Accuracy: 0.0238 Loss: 1.30584180 time: 0.0020s\n",
      "Epoch: 10001 Accuracy: 0.6024 Validation Accuracy: 0.0238 Loss: 1.30584180 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 12.9971s\n",
      "Epoch: 0001 Accuracy: 0.6024 Validation Accuracy: 0.0000 Loss: 1.30584180 time: 0.0020s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-9098ba12c1ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mprev_loss\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprev_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_adj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_adj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-baa07ef15af8>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(adj, features, labels, val_adj, val_features, val_labels, first)\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madj_norm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;31m# validation output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[0mval_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_adj_norm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;31m# Calculate accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\navpr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-eb19bdb07b1f>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, adj)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;31m# Applying activation function sigma (doublerelu) on the layer propogation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdoublerelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#normalize st sum = 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-985ecef6216a>\u001b[0m in \u001b[0;36mdoublerelu\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdoublerelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Start Train\n",
    "prev_loss, op = train(train_adj,train_features,train_labels,val_adj,val_features,val_labels, True)\n",
    "\n",
    "# Keep training recurrently until the loss stops decreasing\n",
    "loss, op = train(train_adj,op.cpu().detach().numpy(),train_labels,val_adj,val_features,val_labels)\n",
    "while loss < prev_loss :\n",
    "    prev_loss = loss\n",
    "    loss, op = train(train_adj,op.cpu().detach().numpy(),train_labels,val_adj,val_features,val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch Basics can be found here:\n",
    "\n",
    "#### Introduction to Pytorch Tensors : https://pytorch.org/tutorials/beginner/introyt/trainingyt.html\n",
    "#### Calculating gradients using Autograd : https://pytorch.org/tutorials/beginner/introyt/autogradyt_tutorial.html\n",
    "#### Building Pytorch Models : https://pytorch.org/tutorials/beginner/introyt/modelsyt_tutorial.html\n",
    "#### Training Pytorch Models : https://pytorch.org/tutorials/beginner/introyt/trainingyt.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
